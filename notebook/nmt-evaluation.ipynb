{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (6.32.1)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.9.18)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.1.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.35.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu datasets transformers sentencepiece protobuf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install safetensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My fine-tuned model vs the baseline MarianMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# # Path to the directory containing the model and config files\n",
    "# model_path = 'marianmt_fine_tuned11'\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# model = MarianMTModel.from_pretrained(model_path)\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# baseline_model_name = 'Helsinki-NLP/opus-mt-fr-en'\n",
    "# baseline_model = MarianMTModel.from_pretrained(baseline_model_name)\n",
    "# baseline_tokenizer = MarianTokenizer.from_pretrained(baseline_model_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# Set source and target languages\n",
    "src_lang = \"fr_XX\"  # French\n",
    "tgt_lang = \"en_XX\"  # English\n",
    "\n",
    "# Example French text\n",
    "fr_text = \"Bonjour, comment ça va ?\"\n",
    "\n",
    "# Tokenize the input text (French)\n",
    "tokenizer.src_lang = src_lang\n",
    "encoded_input = tokenizer(fr_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the translation\n",
    "generated_tokens = model.generate(**encoded_input, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "\n",
    "# Decode the translated text (English)\n",
    "translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the translated text\n",
    "print(f\"Translated Text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the tokenizer and model for facebook/m2m100_418M\n",
    "tokenizer_m2m = AutoTokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "model_m2m = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# Translation function for french to english\n",
    "# def translate_m2m(text, src_lang=\"fr\", tgt_lang=\"en\"):\n",
    "#     # Tokenize the input text with specified language pair\n",
    "#     encoded_input = tokenizer_m2m(text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "#     # Generate translation\n",
    "#     translated = model_m2m.generate(\n",
    "#         **encoded_input,\n",
    "#         forced_bos_token_id=tokenizer_m2m.get_lang_id(tgt_lang)\n",
    "#     )\n",
    "\n",
    "#     # Decode and return the translated text\n",
    "#     translated_text = tokenizer_m2m.decode(translated[0], skip_special_tokens=True)\n",
    "#     return translated_text\n",
    "\n",
    "# # Example usage\n",
    "# fr_text = \"Bonjour, comment ça va ?\"\n",
    "# translated_text = translate_m2m(fr_text)\n",
    "# print(f\"Translated Text: {translated_text}\")  # Should output in English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_translations = [\n",
    "    \"She likes to play tennis with her friends in the afternoon.\",    # Tatoeba\n",
    "    \"The European Parliament has approved new legislation on climate change.\",  # EuroParl\n",
    "    \"I'm just trying to keep my head above water in this city.\",    # OpenSubtitles\n",
    "    \"The United States is a leading global power.\",    # CCMatrix\n",
    "    \"Scientists have discovered a new species of bird in the Amazon rainforest.\",    # News\n",
    "    \"The proposal to increase renewable energy funding has been well received.\",    # EuroParl\n",
    "    \"This cake is delicious, and I think you'll love it.\",    # Tatoeba\n",
    "    \"The company is expanding its operations to new markets in Asia.\",    # CCMatrix\n",
    "    \"They are arguing over the details of the contract.\",    # OpenSubtitles\n",
    "    \"The stock market experienced significant volatility due to economic uncertainty.\",    # News\n",
    "    \"Global warming has become a major issue for governments worldwide.\",    # News\n",
    "    \"You need to make sure you understand the terms before signing the agreement.\",    # OpenSubtitles\n",
    "    \"She gave a speech about the importance of education for all children.\",    # Tatoeba\n",
    "    \"The team was very excited after winning the championship match.\",    # EuroParl\n",
    "    \"The museum has a new exhibit showcasing ancient Roman artifacts.\",    # News\n",
    "    \"Many small businesses are struggling to recover from the economic downturn.\",    # News\n",
    "    \"The development of artificial intelligence is advancing at an incredible pace.\",    # News\n",
    "    \"We will have to work harder to reduce the environmental impact of the industry.\",    # EuroParl\n",
    "    \"He has been practicing his speech for days in preparation for the conference.\",    # Tatoeba\n",
    "    \"The president will address the nation later this evening.\",    # News\n",
    "    \"Electric cars are expected to become more common in the coming years.\",    # News\n",
    "    \"Some cities have started investing heavily in smart city technologies.\",    # News\n",
    "    \"She managed to finish her project ahead of the deadline.\",    # Tatoeba\n",
    "    \"The ambassador met with local leaders to discuss trade agreements.\",    # EuroParl\n",
    "    \"The new healthcare law aims to make medical treatment more affordable for citizens.\",    # News\n",
    "    \"Environmental groups are calling for stricter regulations on carbon emissions.\",    # News\n",
    "    \"We need to reduce our reliance on fossil fuels and focus on renewable energy.\",    # EuroParl\n",
    "    \"The teacher encouraged the students to participate in the debate competition.\",    # Tatoeba\n",
    "    \"The local government is planning to build a new sports facility in the city.\",    # News\n",
    "    \"Scientists are investigating the potential benefits of gene editing.\",    # News\n",
    "    \"There are many factors contributing to the rise in global temperatures.\",    # News\n",
    "    \"The new law will ensure that companies pay fair wages to their employees.\",    # EuroParl\n",
    "    \"She completed her homework and then went out to meet her friends.\",    # Tatoeba\n",
    "    \"Public transport in the city is often delayed due to heavy traffic.\",    # OpenSubtitles\n",
    "    \"The country is experiencing an economic boom thanks to its booming tech industry.\",    # News\n",
    "    \"The mayor spoke about the city's efforts to improve housing affordability.\",    # News\n",
    "    \"This painting was created during the Renaissance period.\",    # Tatoeba\n",
    "    \"The student council organized a fundraiser for the local animal shelter.\",    # Tatoeba\n",
    "    \"After the meeting, they went out for a casual dinner at the new restaurant.\",    # OpenSubtitles\n",
    "    \"The earthquake caused widespread damage to buildings and infrastructure.\",    # News\n",
    "    \"The climate summit will be held in Paris next year.\",    # EuroParl\n",
    "    \"The company is focusing on expanding its presence in Europe and Asia.\",    # CCMatrix\n",
    "    \"He helped his colleague finish the report before the deadline.\",    # Tatoeba\n",
    "    \"Renewable energy sources, such as solar power, are becoming increasingly popular.\",    # News\n",
    "    \"Governments are implementing policies to reduce their carbon footprints.\",    # News\n",
    "    \"The airline has introduced new routes to popular vacation destinations.\",    # News\n",
    "    \"The president delivered a speech on the importance of international cooperation.\",    # EuroParl\n",
    "    \"The local charity is hosting an event to raise funds for underprivileged children.\",    # Tatoeba\n",
    "    \"The new book explores the relationship between humans and technology.\",    # News\n",
    "    \"A growing number of people are moving to urban areas in search of better job opportunities.\",    # News\n",
    "    \"The hotel offers excellent service and beautiful views of the city.\",    # OpenSubtitles\n",
    "    \"She found a new job in a different department within the company.\",    # Tatoeba\n",
    "    \"The politician promised to address the country's housing crisis.\",    # News\n",
    "    \"The president urged people to be patient as the government works to improve the economy.\",    # News\n",
    "    \"The healthcare system in many countries is facing significant challenges.\",    # News\n",
    "    \"International trade agreements are crucial for maintaining global economic stability.\",    # EuroParl\n",
    "    \"He gave an excellent presentation at the conference last week.\",    # Tatoeba\n",
    "    \"The university has introduced new programs for international students.\",    # News\n",
    "    \"Several companies are working together to develop the next generation of smartphones.\",    # News\n",
    "    \"The city is planning to build more parks and green spaces for the public.\",    # News\n",
    "    \"The weather forecast predicts sunny skies and mild temperatures for the weekend.\",    # OpenSubtitles\n",
    "    \"The government is working on improving access to affordable healthcare.\",    # News\n",
    "    \"Several countries are debating the best approach to tackle climate change.\",    # EuroParl\n",
    "    \"The factory produces thousands of units every day to meet demand.\",    # CCMatrix\n",
    "    \"The new system will streamline the process and make it more efficient.\",    # News\n",
    "    \"The company has seen rapid growth over the past few years thanks to its innovative products.\",    # News\n",
    "]\n",
    "\n",
    "source_sentences = [\n",
    "    \"Elle aime jouer au tennis avec ses amis l'après-midi.\",    # Tatoeba\n",
    "    \"Le Parlement européen a approuvé une nouvelle législation sur le changement climatique.\",    # EuroParl\n",
    "    \"Je tente juste de garder la tête hors de l'eau dans cette ville.\",    # OpenSubtitles\n",
    "    \"Les États-Unis sont une puissance mondiale dominante.\",    # CCMatrix\n",
    "    \"Les scientifiques ont découvert une nouvelle espèce d'oiseau dans la forêt amazonienne.\",    # News\n",
    "    \"La proposition d'augmenter le financement des énergies renouvelables a été bien reçue.\",    # EuroParl\n",
    "    \"Ce gâteau est délicieux, et je pense que tu vas l'adorer.\",    # Tatoeba\n",
    "    \"L'entreprise étend ses opérations vers de nouveaux marchés en Asie.\",    # CCMatrix\n",
    "    \"Ils se disputent sur les détails du contrat.\",    # OpenSubtitles\n",
    "    \"La bourse a connu une grande volatilité en raison de l'incertitude économique.\",    # News\n",
    "    \"Le réchauffement climatique est devenu un problème majeur pour les gouvernements du monde entier.\",    # News\n",
    "    \"Tu dois t'assurer de comprendre les termes avant de signer l'accord.\",    # OpenSubtitles\n",
    "    \"Elle a prononcé un discours sur l'importance de l'éducation pour tous les enfants.\",    # Tatoeba\n",
    "    \"L'équipe était très excitée après avoir remporté le match de championnat.\",    # EuroParl\n",
    "    \"Le musée a une nouvelle exposition présentant des artefacts romains antiques.\",    # News\n",
    "    \"De nombreuses petites entreprises ont du mal à se remettre de la récession économique.\",    # News\n",
    "    \"Le développement de l'intelligence artificielle progresse à un rythme incroyable.\",    # News\n",
    "    \"Nous devrons travailler plus dur pour réduire l'impact environnemental de l'industrie.\",    # EuroParl\n",
    "    \"Il a pratiqué son discours pendant des jours en préparation pour la conférence.\",    # Tatoeba\n",
    "    \"Le président s'adressera à la nation ce soir.\",    # News\n",
    "    \"Les voitures électriques devraient devenir plus courantes dans les prochaines années.\",    # News\n",
    "    \"Certaines villes ont commencé à investir massivement dans les technologies de villes intelligentes.\",    # News\n",
    "    \"Elle a réussi à finir son projet avant la date limite.\",    # Tatoeba\n",
    "    \"L'ambassadeur a rencontré les dirigeants locaux pour discuter des accords commerciaux.\",    # EuroParl\n",
    "    \"La nouvelle loi sur la santé vise à rendre les soins médicaux plus abordables pour les citoyens.\",    # News\n",
    "    \"Les groupes environnementaux demandent des régulations plus strictes sur les émissions de carbone.\",    # News\n",
    "    \"Nous devons réduire notre dépendance aux combustibles fossiles et nous concentrer sur les énergies renouvelables.\",    # EuroParl\n",
    "    \"Le professeur a encouragé les étudiants à participer à la compétition de débat.\",    # Tatoeba\n",
    "    \"Le gouvernement local prévoit de construire une nouvelle installation sportive dans la ville.\",    # News\n",
    "    \"Les scientifiques enquêtent sur les avantages potentiels de l'édition génétique.\",    # News\n",
    "    \"Il existe de nombreux facteurs contribuant à la hausse des températures mondiales.\",    # News\n",
    "    \"La nouvelle loi garantira que les entreprises paient des salaires équitables à leurs employés.\",    # EuroParl\n",
    "    \"Elle a terminé ses devoirs puis est sortie retrouver ses amis.\",    # Tatoeba\n",
    "    \"Les transports publics dans la ville sont souvent retardés à cause de la circulation intense.\",    # OpenSubtitles\n",
    "    \"Le pays connaît un boom économique grâce à son industrie technologique florissante.\",    # News\n",
    "    \"Le maire a parlé des efforts de la ville pour améliorer l'accessibilité au logement.\",    # News\n",
    "    \"Ce tableau a été créé pendant la période de la Renaissance.\",    # Tatoeba\n",
    "    \"Le conseil étudiant a organisé une collecte de fonds pour le refuge local pour animaux.\",    # Tatoeba\n",
    "    \"Après la réunion, ils sont allés dîner de manière informelle dans le nouveau restaurant.\",    # OpenSubtitles\n",
    "    \"Le tremblement de terre a causé des dégâts importants aux bâtiments et aux infrastructures.\",    # News\n",
    "    \"Le sommet climatique se tiendra à Paris l'année prochaine.\",    # EuroParl\n",
    "    \"L'entreprise se concentre sur l'expansion de sa présence en Europe et en Asie.\",    # CCMatrix\n",
    "    \"Il a aidé son collègue à terminer le rapport avant la date limite.\",    # Tatoeba\n",
    "    \"Les sources d'énergie renouvelable, telles que l'énergie solaire, sont de plus en plus populaires.\",    # News\n",
    "    \"Les gouvernements mettent en place des politiques pour réduire leur empreinte carbone.\",    # News\n",
    "    \"La compagnie aérienne a introduit de nouvelles lignes vers des destinations de vacances populaires.\",    # News\n",
    "    \"Le président a prononcé un discours sur l'importance de la coopération internationale.\",    # EuroParl\n",
    "    \"La charité locale organise un événement pour collecter des fonds pour les enfants défavorisés.\",    # Tatoeba\n",
    "    \"Le nouveau livre explore la relation entre l'homme et la technologie.\",    # News\n",
    "    \"Un nombre croissant de personnes déménagent dans les zones urbaines à la recherche de meilleures opportunités d'emploi.\",    # News\n",
    "    \"L'hôtel offre un excellent service et de belles vues sur la ville.\",    # OpenSubtitles\n",
    "    \"Elle a trouvé un nouveau poste dans un autre département au sein de l'entreprise.\",    # Tatoeba\n",
    "    \"Le politicien a promis de s'attaquer à la crise du logement du pays.\",    # News\n",
    "    \"Le président a exhorté les citoyens à être patients pendant que le gouvernement travaille pour améliorer l'économie.\",    # News\n",
    "    \"Le système de santé de nombreux pays fait face à des défis importants.\",    # News\n",
    "    \"Les accords commerciaux internationaux sont cruciaux pour maintenir la stabilité économique mondiale.\",    # EuroParl\n",
    "    \"Il a fait une excellente présentation lors de la conférence la semaine dernière.\",    # Tatoeba\n",
    "    \"L'université a introduit de nouveaux programmes pour les étudiants internationaux.\",    # News\n",
    "    \"Plusieurs entreprises collaborent pour développer la prochaine génération de smartphones.\",    # News\n",
    "    \"La ville prévoit de construire plus de parcs et d'espaces verts pour le public.\",    # News\n",
    "    \"Les prévisions météorologiques annoncent des ciels ensoleillés et des températures modérées pour le week-end.\",    # OpenSubtitles\n",
    "    \"Le gouvernement travaille à améliorer l'accès aux soins de santé abordables.\",    # News\n",
    "    \"Plusieurs pays débattent de la meilleure approche pour lutter contre le changement climatique.\",    # EuroParl\n",
    "    \"L'usine produit des milliers d'unités chaque jour pour répondre à la demande.\",    # CCMatrix\n",
    "    \"Le nouveau système simplifiera le processus et le rendra plus efficace.\",    # News\n",
    "    \"L'entreprise a connu une croissance rapide ces dernières années grâce à ses produits innovants.\",    # News\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import sacrebleu\n",
    "\n",
    "# def translate_sentences(sentences, model, tokenizer, batch_size=16):\n",
    "#     model.eval()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "\n",
    "#     all_translations = []\n",
    "\n",
    "#     for i in range(0, len(sentences), batch_size):\n",
    "#         batch = sentences[i:i+batch_size]\n",
    "#         inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             translated = model.generate(**inputs, max_length=512)\n",
    "#         decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "#         all_translations.extend(decoded)\n",
    "\n",
    "#         # Free memory\n",
    "#         del inputs, translated, decoded\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     return all_translations\n",
    "    \n",
    "# all_translations = translate_sentences(source_sentences, model, tokenizer)\n",
    "# all_translations_custom = translate_sentences(source_sentences, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Translation function\n",
    "def translate_sentences_mbart(sentences, model, tokenizer, src_lang=\"fr_XX\", tgt_lang=\"en_XX\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Set the source language for the tokenizer\n",
    "    tokenizer.src_lang = src_lang\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch of sentences (with padding and truncation)\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "        \n",
    "        # Decode the generated tokens into readable text\n",
    "        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del inputs, generated_tokens, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "def translate_m2m_batch(sentences, model, tokenizer, src_lang=\"fr\", tgt_lang=\"en\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Get the target language ID\n",
    "    tgt_lang_id = tokenizer.get_lang_id(tgt_lang)\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "\n",
    "        # Tokenize the batch of sentences\n",
    "        encoded_input = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            translated = model.generate(\n",
    "                **encoded_input,\n",
    "                forced_bos_token_id=tgt_lang_id\n",
    "            )\n",
    "\n",
    "        # Decode the generated translations\n",
    "        decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del encoded_input, translated, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "all_translations = translate_sentences_mbart(source_sentences, model, tokenizer)\n",
    "all_translations_custom = translate_m2m_batch(source_sentences, model_m2m, tokenizer_m2m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu Score\n",
    "Exact word/phrase matching — how much of the machine translation is in direct alignment with the reference translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BLEU Score: 68.08\n",
      "Custom BLEU Score: 25.16\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Flatten the reference translations list (since it's a list of lists)\n",
    "references = [ref for ref in reference_translations]\n",
    "    \n",
    "# Calculate BLEU score for the baseline model\n",
    "bleu_custom = sacrebleu.corpus_bleu(all_translations_custom, [references], lowercase=True, tokenize='13a')\n",
    "bleu_baseline = sacrebleu.corpus_bleu(all_translations, [references], lowercase=True, tokenize='13a')\n",
    "\n",
    "print(f\"Baseline BLEU Score: {bleu_baseline.score:.2f}\")\n",
    "print(f\"Custom BLEU Score: {bleu_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TER Score\n",
    "Measures the number of edits (insertions, deletions, substitutions) needed to change the hypothesis into the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER for baseline: 18.51\n",
      "TER for custom: 71.22\n"
     ]
    }
   ],
   "source": [
    "ter_custom = sacrebleu.corpus_ter(all_translations_custom, [references])\n",
    "ter_score = sacrebleu.corpus_ter(all_translations, [references])\n",
    "\n",
    "print(f\"TER for baseline: {ter_score.score:.2f}\")\n",
    "print(f\"TER for custom: {ter_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChrF score\n",
    "Works better for languages with complex morphology.\n",
    "\n",
    "Can detect character-level errors (typos, word segmentation issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrF for baseline: 81.79\n",
      "ChrF for custom: 50.86\n"
     ]
    }
   ],
   "source": [
    "# ChrF (default settings, good for many languages)\n",
    "chrf_score = sacrebleu.corpus_chrf(all_translations, [references])\n",
    "chrf_custom = sacrebleu.corpus_chrf(all_translations_custom, [references])\n",
    "\n",
    "print(f\"ChrF for baseline: {chrf_score.score:.2f}\")\n",
    "print(f\"ChrF for custom: {chrf_custom.score:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE-L\n",
    "Captures content overlap, which makes it suitable for evaluation tasks where fluency and content preservation are crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting nltk (from rouge-score)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score) (1.16.0)\n",
      "Collecting click (from nltk->rouge-score)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk->rouge-score)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24988 sha256=ef38fee5440216097a91a260a642a0d2d2495e145c904ff5214594b457999315\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: joblib, click, absl-py, nltk, rouge-score\n",
      "Successfully installed absl-py-2.3.1 click-8.3.0 joblib-1.5.2 nltk-3.9.1 rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg ROUGE-L for baseline: 86.79\n",
      "Avg ROUGE-L for custom: 45.32\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ROUGE-L (using rouge_score package)\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "rouge_l_scores = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations)]\n",
    "avg_rouge_l = 100 * sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "print(f\"Avg ROUGE-L for baseline: {avg_rouge_l:.2f}\")\n",
    "\n",
    "rouge_l_scores_custom = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations_custom)]\n",
    "avg_rouge_l_for_custom = 100 * sum(rouge_l_scores_custom) / len(rouge_l_scores_custom)\n",
    "\n",
    "print(f\"Avg ROUGE-L for custom: {avg_rouge_l_for_custom:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC   : Elle aime jouer au tennis avec ses amis l'après-midi.\n",
      "REF   : She likes to play tennis with her friends in the afternoon.\n",
      "BASE  : She likes to play tennis with her friends in the afternoon.\n",
      "CUSTOM: She loves to play tennis with her friends the afternoon.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le Parlement européen a approuvé une nouvelle législation sur le changement climatique.\n",
      "REF   : The European Parliament has approved new legislation on climate change.\n",
      "BASE  : The European Parliament has approved new legislation on climate change.\n",
      "CUSTOM: The European Parliament approved a new legislation on climate change.\n",
      "------------------------------------------------------------\n",
      "SRC   : Je tente juste de garder la tête hors de l'eau dans cette ville.\n",
      "REF   : I'm just trying to keep my head above water in this city.\n",
      "BASE  : I'm just trying to keep my head out of the water in this city.\n",
      "CUSTOM: I try just de garder la tête hors de l'eau dans cette ville.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les États-Unis sont une puissance mondiale dominante.\n",
      "REF   : The United States is a leading global power.\n",
      "BASE  : The United States is a dominant global power.\n",
      "CUSTOM: The United States is a world dominant power.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les scientifiques ont découvert une nouvelle espèce d'oiseau dans la forêt amazonienne.\n",
      "REF   : Scientists have discovered a new species of bird in the Amazon rainforest.\n",
      "BASE  : Scientists have discovered a new species of bird in the Amazon forest.\n",
      "CUSTOM: The scientists have discovered a new species of bird in the Amazon forest.\n",
      "------------------------------------------------------------\n",
      "SRC   : La proposition d'augmenter le financement des énergies renouvelables a été bien reçue.\n",
      "REF   : The proposal to increase renewable energy funding has been well received.\n",
      "BASE  : The proposal to increase funding for renewable energies was well received.\n",
      "CUSTOM: La proposition d'augmenter le financement des énergies renovables a été bien reçue.\n",
      "------------------------------------------------------------\n",
      "SRC   : Ce gâteau est délicieux, et je pense que tu vas l'adorer.\n",
      "REF   : This cake is delicious, and I think you'll love it.\n",
      "BASE  : This cake is delicious, and I think you will love it.\n",
      "CUSTOM: Ce gâteau est délicieux, et je pense que tu vas l'adorer.\n",
      "------------------------------------------------------------\n",
      "SRC   : L'entreprise étend ses opérations vers de nouveaux marchés en Asie.\n",
      "REF   : The company is expanding its operations to new markets in Asia.\n",
      "BASE  : The company is expanding its operations to new markets in Asia.\n",
      "CUSTOM: The company extends its operations versus de nouveaux marchés en Asia.\n",
      "------------------------------------------------------------\n",
      "SRC   : Ils se disputent sur les détails du contrat.\n",
      "REF   : They are arguing over the details of the contract.\n",
      "BASE  : They dispute the details of the contract.\n",
      "CUSTOM: They are disputed on the details of the contract.\n",
      "------------------------------------------------------------\n",
      "SRC   : La bourse a connu une grande volatilité en raison de l'incertitude économique.\n",
      "REF   : The stock market experienced significant volatility due to economic uncertainty.\n",
      "BASE  : The stock market has experienced great volatility due to economic uncertainty.\n",
      "CUSTOM: The stock exchange has known a great volatility due to the economic uncertainty.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le réchauffement climatique est devenu un problème majeur pour les gouvernements du monde entier.\n",
      "REF   : Global warming has become a major issue for governments worldwide.\n",
      "BASE  : Climate warming has become a major problem for governments around the world.\n",
      "CUSTOM: Climate warming has become a major problem for the governments of the whole world.\n",
      "------------------------------------------------------------\n",
      "SRC   : Tu dois t'assurer de comprendre les termes avant de signer l'accord.\n",
      "REF   : You need to make sure you understand the terms before signing the agreement.\n",
      "BASE  : You must ensure that you understand the terms before signing the agreement.\n",
      "CUSTOM: You must ensure that you understand the terms before signing the agreement.\n",
      "------------------------------------------------------------\n",
      "SRC   : Elle a prononcé un discours sur l'importance de l'éducation pour tous les enfants.\n",
      "REF   : She gave a speech about the importance of education for all children.\n",
      "BASE  : She made a speech on the importance of education for all children.\n",
      "CUSTOM: It has a prononcé a discourse on the importance of education for all the children.\n",
      "------------------------------------------------------------\n",
      "SRC   : L'équipe était très excitée après avoir remporté le match de championnat.\n",
      "REF   : The team was very excited after winning the championship match.\n",
      "BASE  : The team was very excited after winning the championship match.\n",
      "CUSTOM: The team was very excited after having won the match of championship.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le musée a une nouvelle exposition présentant des artefacts romains antiques.\n",
      "REF   : The museum has a new exhibit showcasing ancient Roman artifacts.\n",
      "BASE  : The museum has a new exhibition presenting ancient Roman artifacts.\n",
      "CUSTOM: Le musée a une nouvelle exposition presentant des artefacts romains antiques.\n",
      "------------------------------------------------------------\n",
      "SRC   : De nombreuses petites entreprises ont du mal à se remettre de la récession économique.\n",
      "REF   : Many small businesses are struggling to recover from the economic downturn.\n",
      "BASE  : Many small businesses are struggling to recover from the economic recession.\n",
      "CUSTOM: Many small enterprises have hard to remettre of the economic recession.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le développement de l'intelligence artificielle progresse à un rythme incroyable.\n",
      "REF   : The development of artificial intelligence is advancing at an incredible pace.\n",
      "BASE  : The development of artificial intelligence is progressing at an incredible pace.\n",
      "CUSTOM: The development of artificial intelligence progresses at an incredible pace.\n",
      "------------------------------------------------------------\n",
      "SRC   : Nous devrons travailler plus dur pour réduire l'impact environnemental de l'industrie.\n",
      "REF   : We will have to work harder to reduce the environmental impact of the industry.\n",
      "BASE  : We will have to work harder to reduce the environmental impact of the industry.\n",
      "CUSTOM: We must work more hard to reduce the environmental impact of the industry.\n",
      "------------------------------------------------------------\n",
      "SRC   : Il a pratiqué son discours pendant des jours en préparation pour la conférence.\n",
      "REF   : He has been practicing his speech for days in preparation for the conference.\n",
      "BASE  : He conducted his speech for days in preparation for the conference.\n",
      "CUSTOM: A practiced son speaks during days in preparation for the conference.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le président s'adressera à la nation ce soir.\n",
      "REF   : The president will address the nation later this evening.\n",
      "BASE  : The President will address the nation tonight.\n",
      "CUSTOM: The President addresses to the nation tonight.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(source_sentences)):\n",
    "    print(f\"SRC   : {source_sentences[i]}\")\n",
    "    print(f\"REF   : {reference_translations[i]}\")\n",
    "    print(f\"BASE  : {all_translations[i]}\")\n",
    "    print(f\"CUSTOM: {all_translations_custom[i]}\")\n",
    "    # print(f\"Facebook: {all_translations_facebook[i]}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Optional: limit output (e.g., to first 20 examples)\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_set 2 (newsdiscusstest2015-enfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les demeurés de UKIP qui refusent ceux qui viv...</td>\n",
       "      <td>This is perfectly illustrated by the UKIP numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous parlez de quand Nigel Farage dit que le N...</td>\n",
       "      <td>You mean Nigel Farage saying the NHS should no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D'abord vous utilisez des arguments spécieux, ...</td>\n",
       "      <td>You raise a straw man and then knock it down w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaque fois que moi ou ma famille avons besoin...</td>\n",
       "      <td>Every time I or my family need to use the NHS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je crois que c'est vous qui utilisez des argum...</td>\n",
       "      <td>I think the straw man is yours.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Et si la règle est la même qu'ici l'état est s...</td>\n",
       "      <td>And if the rule is the same as here, the state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Ils vont peut-etre payer les satellites en fré...</td>\n",
       "      <td>They are going to perhaps pay for the satellit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Cela est d'autant plus fâcheux que de nombreux...</td>\n",
       "      <td>That is all the more regrettable since a lot o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Au total cela crée une impression erronée cont...</td>\n",
       "      <td>All in all that creates an erroneous impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Tout à fait d'accord avec vous, le titre n'est...</td>\n",
       "      <td>Totally in agreement with you, the title is no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 french  \\\n",
       "0     Les demeurés de UKIP qui refusent ceux qui viv...   \n",
       "1     Vous parlez de quand Nigel Farage dit que le N...   \n",
       "2     D'abord vous utilisez des arguments spécieux, ...   \n",
       "3     Chaque fois que moi ou ma famille avons besoin...   \n",
       "4     Je crois que c'est vous qui utilisez des argum...   \n",
       "...                                                 ...   \n",
       "1495  Et si la règle est la même qu'ici l'état est s...   \n",
       "1496  Ils vont peut-etre payer les satellites en fré...   \n",
       "1497  Cela est d'autant plus fâcheux que de nombreux...   \n",
       "1498  Au total cela crée une impression erronée cont...   \n",
       "1499  Tout à fait d'accord avec vous, le titre n'est...   \n",
       "\n",
       "                                                english  \n",
       "0     This is perfectly illustrated by the UKIP numb...  \n",
       "1     You mean Nigel Farage saying the NHS should no...  \n",
       "2     You raise a straw man and then knock it down w...  \n",
       "3     Every time I or my family need to use the NHS ...  \n",
       "4                       I think the straw man is yours.  \n",
       "...                                                 ...  \n",
       "1495  And if the rule is the same as here, the state...  \n",
       "1496  They are going to perhaps pay for the satellit...  \n",
       "1497  That is all the more regrettable since a lot o...  \n",
       "1498  All in all that creates an erroneous impressio...  \n",
       "1499  Totally in agreement with you, the title is no...  \n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the French file\n",
    "with open('testing_dataset/newsdiscusstest2015-enfr.fr', 'r', encoding='utf-8') as f_fr:\n",
    "    french_sentences = [line.strip() for line in f_fr]\n",
    "\n",
    "# Read the aligned English file\n",
    "with open('testing_dataset/newsdiscusstest2015-enfr.en', 'r', encoding='utf-8') as f_en:\n",
    "    english_sentences = [line.strip() for line in f_en]\n",
    "\n",
    "# Make sure both have the same number of lines\n",
    "assert len(french_sentences) == len(english_sentences), \"Files are not aligned!\"\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'french': french_sentences,\n",
    "    'english': english_sentences\n",
    "})\n",
    "\n",
    "# Optional: Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Preview\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences = dataset['french']\n",
    "reference_translations = dataset['english']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import sacrebleu\n",
    "\n",
    "# def translate_sentences(sentences, model, tokenizer, batch_size=16):\n",
    "#     model.eval()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "\n",
    "#     all_translations = []\n",
    "\n",
    "#     for i in range(0, len(sentences), batch_size):\n",
    "#         batch = sentences[i:i+batch_size]\n",
    "#         inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             translated = model.generate(**inputs, max_length=512)\n",
    "#         decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "#         all_translations.extend(decoded)\n",
    "\n",
    "#         # Free memory\n",
    "#         del inputs, translated, decoded\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     return all_translations\n",
    "    \n",
    "# all_translations = translate_sentences(source_sentences, baseline_model, baseline_tokenizer)\n",
    "# all_translations_custom = translate_sentences(source_sentences, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Translation function\n",
    "def translate_sentences_mbart(sentences, model, tokenizer, src_lang=\"fr_XX\", tgt_lang=\"en_XX\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Set the source language for the tokenizer\n",
    "    tokenizer.src_lang = src_lang\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch of sentences (with padding and truncation)\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "        \n",
    "        # Decode the generated tokens into readable text\n",
    "        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del inputs, generated_tokens, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "def translate_m2m_batch(sentences, model, tokenizer, src_lang=\"fr\", tgt_lang=\"en\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Get the target language ID\n",
    "    tgt_lang_id = tokenizer.get_lang_id(tgt_lang)\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "\n",
    "        # Tokenize the batch of sentences\n",
    "        encoded_input = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            translated = model.generate(\n",
    "                **encoded_input,\n",
    "                forced_bos_token_id=tgt_lang_id\n",
    "            )\n",
    "\n",
    "        # Decode the generated translations\n",
    "        decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del encoded_input, translated, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "all_translations = translate_sentences_mbart(source_sentences, model, tokenizer)\n",
    "all_translations_custom = translate_m2m_batch(source_sentences, model_m2m, tokenizer_m2m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu Score\n",
    "Exact word/phrase matching — how much of the machine translation is in direct alignment with the reference translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BLEU Score: 37.23\n",
      "Custom BLEU Score: 10.55\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Flatten the reference translations list (since it's a list of lists)\n",
    "references = [ref for ref in reference_translations]\n",
    "    \n",
    "# Calculate BLEU score for the baseline model\n",
    "bleu_custom = sacrebleu.corpus_bleu(all_translations_custom, [references], lowercase=True, tokenize='13a')\n",
    "bleu_baseline = sacrebleu.corpus_bleu(all_translations, [references], lowercase=True, tokenize='13a')\n",
    "\n",
    "print(f\"Baseline BLEU Score: {bleu_baseline.score:.2f}\")\n",
    "print(f\"Custom BLEU Score: {bleu_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TER Score\n",
    "Measures the number of edits (insertions, deletions, substitutions) needed to change the hypothesis into the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER for baseline: 50.40\n",
      "TER for custom: 89.32\n"
     ]
    }
   ],
   "source": [
    "ter_custom = sacrebleu.corpus_ter(all_translations_custom, [references])\n",
    "ter_score = sacrebleu.corpus_ter(all_translations, [references])\n",
    "\n",
    "print(f\"TER for baseline: {ter_score.score:.2f}\")\n",
    "print(f\"TER for custom: {ter_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChrF score\n",
    "Works better for languages with complex morphology.\n",
    "\n",
    "Can detect character-level errors (typos, word segmentation issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrF for baseline: 59.31\n",
      "ChrF for custom: 35.24\n"
     ]
    }
   ],
   "source": [
    "# ChrF (default settings, good for many languages)\n",
    "chrf_score = sacrebleu.corpus_chrf(all_translations, [references])\n",
    "chrf_custom = sacrebleu.corpus_chrf(all_translations_custom, [references])\n",
    "\n",
    "print(f\"ChrF for baseline: {chrf_score.score:.2f}\")\n",
    "print(f\"ChrF for custom: {chrf_custom.score:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE-L\n",
    "Captures content overlap, which makes it suitable for evaluation tasks where fluency and content preservation are crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg ROUGE-L for baseline: 63.48\n",
      "Avg ROUGE-L for custom: 33.24\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ROUGE-L (using rouge_score package)\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "rouge_l_scores = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations)]\n",
    "avg_rouge_l = 100 * sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "print(f\"Avg ROUGE-L for baseline: {avg_rouge_l:.2f}\")\n",
    "\n",
    "rouge_l_scores_custom = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations_custom)]\n",
    "avg_rouge_l_for_custom = 100 * sum(rouge_l_scores_custom) / len(rouge_l_scores_custom)\n",
    "\n",
    "print(f\"Avg ROUGE-L for custom: {avg_rouge_l_for_custom:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC   : Les demeurés de UKIP qui refusent ceux qui vivent avec le VIH sont un exemple parfait.\n",
      "REF   : This is perfectly illustrated by the UKIP numbties banning people with HIV.\n",
      "BASE  : The remainder of UKIP who reject those living with HIV are a perfect example.\n",
      "CUSTOM: The demeurés of UKIP who refuse those who live with HIV are an example perfect.\n",
      "------------------------------------------------------------\n",
      "SRC   : Vous parlez de quand Nigel Farage dit que le NHS ne doit pas servir à payer pour ceux qui viennent au Royaume-Uni faire du tourisme de santé, et quand, avec ça à l'esprit, il répond oui quand l'intervieweur lui demande spécifiquement si les personnes vivant avec le VIH sont inclus dans les indésirables.\n",
      "REF   : You mean Nigel Farage saying the NHS should not be used to pay for people coming to the UK as health tourists, and saying yes when the interviewer specifically asked if, with the aforementioned in mind, people with HIV were included in not being welcome.\n",
      "BASE  : You are talking about when Nigel Farage says that the NHS should not be used to pay for those who come to the UK to do health tourism, and when, with that in mind, he answers yes when the interviewer specifically asks him if people living with HIV are included in the undesirable.\n",
      "CUSTOM: You speak of when Nigel Farage says that the NHS ne doit pas servir à payer pour ceux qui viennent au Royaume-Uni faire du tourisme de santé, et quand, avec ça à l'esprit, il répond oui quand l'intervieweur lui demande spécifiquement si les personnes vivant avec le VIH sont inclus dans les indésirables.\n",
      "------------------------------------------------------------\n",
      "SRC   : D'abord vous utilisez des arguments spécieux, puis vous les discréditer par une homophobie à peine voilé.\n",
      "REF   : You raise a straw man and then knock it down with thinly veiled homophobia.\n",
      "BASE  : First you use special arguments, then you discredit them with barely visible homophobia.\n",
      "CUSTOM: First you use des arguments spécieux, puis vous les discréditer par une homophobie à peine voilé.\n",
      "------------------------------------------------------------\n",
      "SRC   : Chaque fois que moi ou ma famille avons besoin du NHS, nous devons faire la queue derrière des intolérants à l'hypocondrie chronique qui pensent que tout leur est dû.\n",
      "REF   : Every time I or my family need to use the NHS we have to queue up behind bigots with a sense of entitlement and chronic hypochondria.\n",
      "BASE  : Every time I or my family need NHS, we have to stand behind chronic hypochondriacs who think they deserve it all.\n",
      "CUSTOM: Every time that my family needs NHS, we must make the quue derrière des intolerants à l'hypocondrie chronique qui pensent que tout leur est dû.\n",
      "------------------------------------------------------------\n",
      "SRC   : Je crois que c'est vous qui utilisez des arguments spécieux.\n",
      "REF   : I think the straw man is yours.\n",
      "BASE  : I think it is you who are using special arguments.\n",
      "CUSTOM: I believe that it is you who uses the specific arguments.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le tourisme de santé, tel que défini par les cinglés de droite, n'existe pratiquement pas.\n",
      "REF   : Health tourism as defined by the right wing loonies is virtually none existent.\n",
      "BASE  : Health tourism, as defined by the right-wing cyclists, is virtually non-existent.\n",
      "CUSTOM: Le tourisme de santé, tel que défini par les cinglés de droite, n'existe pratiquement pas.\n",
      "------------------------------------------------------------\n",
      "SRC   : Je crois que c'est ce qu'on appelle la démocratie.\n",
      "REF   : I think it's called democracy.\n",
      "BASE  : I believe that this is what is called democracy.\n",
      "CUSTOM: I believe that is what we call democracy.\n",
      "------------------------------------------------------------\n",
      "SRC   : Alors personne ne serait affecté par les mesures de UKIP contre le tourisme de santé, donc il n'y a aucun problème.\n",
      "REF   : So no one would be affected by UKIP's policies against health tourism so no problem.\n",
      "BASE  : So no one would be affected by UKIP's measures against health tourism, so there is no problem.\n",
      "CUSTOM: Therefore no one would be affected by the measures of UKIP against the tourism of health, therefore there is no problem.\n",
      "------------------------------------------------------------\n",
      "SRC   : Il n'y a que dans l'univers parallèle de UKIP que Carswell peut apparaître comme un révolutionnaire.\n",
      "REF   : Only in UKIP La La Land could Carswell be described as revolutionary.\n",
      "BASE  : Only in the parallel universe of UKIP can Carswell appear to be a revolutionary.\n",
      "CUSTOM: There is no one that dans l'univers parallèle de UKIP that Carswell can appear as a revolutionary.\n",
      "------------------------------------------------------------\n",
      "SRC   : Une citation tirée d'un torchon ne constitue par une preuve.\n",
      "REF   : Quoting the bollox The Daily Muck spew out is not evidence.\n",
      "BASE  : A citation from a torch does not constitute evidence.\n",
      "CUSTOM: A quote tirée d'un torchon ne constitutes par une preuve.\n",
      "------------------------------------------------------------\n",
      "SRC   : Oui, tirez donc sur le messager.\n",
      "REF   : Ah, shoot the messenger.\n",
      "BASE  : Yes, so lean on the messenger.\n",
      "CUSTOM: Yes, thus tirez on the messenger.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le Mail n'a pas écrit le rapport, il n'a fait que le commenter.\n",
      "REF   : The Mail didn't write the report, it merely commented on it.\n",
      "BASE  : The Mail did not write the report, it merely commented on it.\n",
      "CUSTOM: Le Mail n'a pas écrit le rapport, il n'a fait que le commenter.\n",
      "------------------------------------------------------------\n",
      "SRC   : Ceux qui contrôlent la majorité des médias dans ce pays devraient être fusillés pour avoir propagé une telle propagande populiste comme si c'était la réalité.\n",
      "REF   : Whoever controls most of the media in this country should undead be shot for spouting populist propaganda as fact.\n",
      "BASE  : Those who control the majority of the media in this country should be shot for spreading such populist propaganda as if it were real.\n",
      "CUSTOM: Those who control the majority of the media in what pays should be fusillés to have propagated a telle propaganda populiste as si c'était la réalité.\n",
      "------------------------------------------------------------\n",
      "SRC   : Je ne pense pas que vous sachiez ce qu'est un argument spécieux.\n",
      "REF   : I don't think you know what a straw man is.\n",
      "BASE  : I do not think you know what a special argument is.\n",
      "CUSTOM: I don't think that you know what's a special argument.\n",
      "------------------------------------------------------------\n",
      "SRC   : Vous ne savez rien non plus de ma situation personnelle ou de mon identité, alors vous devriez faire attention quand vous tentez de tuer le débat par des accusations d'homophobie.\n",
      "REF   : You also don't know anything about my personal circumstances or identity so I would be very careful about trying to eradicate a debate with accusations of homophobia.\n",
      "BASE  : Nor do you know anything about my personal situation or identity, so you should pay attention when you try to kill the debate with accusations of homophobia.\n",
      "CUSTOM: You don't know anything no plus de ma situation personelle ou de mon identité, then you must pay attention when you try to take the debate by the accusations of homophobia.\n",
      "------------------------------------------------------------\n",
      "SRC   : La phrase de Farage a beaucoup surpris, mais seulement parce qu'on parle si rarement de ce problème.\n",
      "REF   : Farage's comment came as quite a shock, but only because it is so rarely addressed.\n",
      "BASE  : Farage's phrase was very surprising, but only because this problem is so rarely discussed.\n",
      "CUSTOM: La phrase de Farage a beaucoup surpris, mais seulement parce qu'on parle si rarement de ce problem.\n",
      "------------------------------------------------------------\n",
      "SRC   : Il n'a fait absolument aucune remarque homophobe.\n",
      "REF   : He did not express any homophobic beliefs whatsoever.\n",
      "BASE  : He made absolutely no homophobic remarks.\n",
      "CUSTOM: There is absolutely no remarks homophobic.\n",
      "------------------------------------------------------------\n",
      "SRC   : Il va falloir que vous réussissiez à vous en remettre.\n",
      "REF   : You will just have to find a way of getting over it.\n",
      "BASE  : You will need to succeed in getting it back.\n",
      "CUSTOM: It will falloir that you succeed to you in remettre.\n",
      "------------------------------------------------------------\n",
      "SRC   : Je ne suis pas bien sûr d'où vous voulez en venir, mais j'imagine que vous n'aimez pas quand les médias parlent de ce que vous n'aimez pas.\n",
      "REF   : I'm not entirely sure what you're trying to say, but my guess is that you dislike the media reporting things you disagree with.\n",
      "BASE  : I'm not sure where you're coming from, but I imagine you don't like when the media talks about what you don't like.\n",
      "CUSTOM: I'm not well sure where you want to come, but I'm imagining that you don't like when the media speak of what you don't like.\n",
      "------------------------------------------------------------\n",
      "SRC   : On en parle si rarement parce que contrairement à Farage et à ses disciples cinglés de Thatcher qui pensent que le sida et les inondations sont un signe de dieu et non pas une réflexion sur leur propre incapacité à comprendre que les complexités de l'humanité sont quelque chose de bien, alors non.\n",
      "REF   : It is so rarely addressed because unlike Fararge and his Thatcherite loony disciples who think aids and floods are a signal from the divine and not a reflection on their own ignorance in understanding the complexities of humanity as something to celebrate,then no.\n",
      "BASE  : It is so rarely spoken of because, contrary to Farage and his cingled disciples of Thatcher who think that AIDS and floods are a sign of God and not a reflection on their own inability to understand that the complexities of humanity are something good, then not.\n",
      "CUSTOM: On en parle si rarement parce que contrirement à Farage et à ses disciples cinglés de Thatcher qui pensent que le sida et les inondations sont un signe de dieu et non pas une réflexion sur leur propre incapacité à comprendre que les complexités de l'humanité sont quelque chose de bien, alors non.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(source_sentences)):\n",
    "    print(f\"SRC   : {source_sentences[i]}\")\n",
    "    print(f\"REF   : {reference_translations[i]}\")\n",
    "    print(f\"BASE  : {all_translations[i]}\")\n",
    "    print(f\"CUSTOM: {all_translations_custom[i]}\")\n",
    "    # print(f\"Facebook: {all_translations_facebook[i]}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Optional: limit output (e.g., to first 20 examples)\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test_set 3 (news-test2008)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'inflation, en Europe, a dérapé sur l'aliment...</td>\n",
       "      <td>Food: Where European inflation slipped up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L'inflation accélérée, mesurée dans la zone eu...</td>\n",
       "      <td>The skyward zoom in food prices is the dominan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En novembre, l'augmentation des prix, dans les...</td>\n",
       "      <td>November price hikes were higher than expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Les prévisions officielles n'ont indiqué que 3...</td>\n",
       "      <td>Official forecasts predicted just 3 percent, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contrairement aux banques centrales américaine...</td>\n",
       "      <td>As opposed to the US, UK, and Canadian central...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Le poker encore difficilement prévisible sur F...</td>\n",
       "      <td>The months-long and at this stage fairly uncle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>Freenet avait à la fin du troisième trimestre ...</td>\n",
       "      <td>At the close of the third quarter, Freenet had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>La Holding de United Internet et Drillisch dét...</td>\n",
       "      <td>The holding of United Internet and Drillisch h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>Il a été désormais convenu que Drillisch appor...</td>\n",
       "      <td>Now, it had been arranged for Drillisch to acq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>Le droit d'acheter les 18,49 pour cent de la s...</td>\n",
       "      <td>The option to buy 18.49 percent from investmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 french  \\\n",
       "0     L'inflation, en Europe, a dérapé sur l'aliment...   \n",
       "1     L'inflation accélérée, mesurée dans la zone eu...   \n",
       "2     En novembre, l'augmentation des prix, dans les...   \n",
       "3     Les prévisions officielles n'ont indiqué que 3...   \n",
       "4     Contrairement aux banques centrales américaine...   \n",
       "...                                                 ...   \n",
       "2046  Le poker encore difficilement prévisible sur F...   \n",
       "2047  Freenet avait à la fin du troisième trimestre ...   \n",
       "2048  La Holding de United Internet et Drillisch dét...   \n",
       "2049  Il a été désormais convenu que Drillisch appor...   \n",
       "2050  Le droit d'acheter les 18,49 pour cent de la s...   \n",
       "\n",
       "                                                english  \n",
       "0             Food: Where European inflation slipped up  \n",
       "1     The skyward zoom in food prices is the dominan...  \n",
       "2     November price hikes were higher than expected...  \n",
       "3     Official forecasts predicted just 3 percent, B...  \n",
       "4     As opposed to the US, UK, and Canadian central...  \n",
       "...                                                 ...  \n",
       "2046  The months-long and at this stage fairly uncle...  \n",
       "2047  At the close of the third quarter, Freenet had...  \n",
       "2048  The holding of United Internet and Drillisch h...  \n",
       "2049  Now, it had been arranged for Drillisch to acq...  \n",
       "2050  The option to buy 18.49 percent from investmen...  \n",
       "\n",
       "[2051 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the French file\n",
    "with open('testing_dataset/news-test2008.fr', 'r', encoding='utf-8') as f_fr:\n",
    "    french_sentences = [line.strip() for line in f_fr]\n",
    "\n",
    "# Read the aligned English file\n",
    "with open('testing_dataset/news-test2008.en', 'r', encoding='utf-8') as f_en:\n",
    "    english_sentences = [line.strip() for line in f_en]\n",
    "\n",
    "# Make sure both have the same number of lines\n",
    "assert len(french_sentences) == len(english_sentences), \"Files are not aligned!\"\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'french': french_sentences,\n",
    "    'english': english_sentences\n",
    "})\n",
    "\n",
    "# Optional: Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Preview\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences = dataset['french']\n",
    "reference_translations = dataset['english']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import sacrebleu\n",
    "\n",
    "# def translate_sentences(sentences, model, tokenizer, batch_size=16):\n",
    "#     model.eval()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "\n",
    "#     all_translations = []\n",
    "\n",
    "#     for i in range(0, len(sentences), batch_size):\n",
    "#         batch = sentences[i:i+batch_size]\n",
    "#         inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             translated = model.generate(**inputs, max_length=512)\n",
    "#         decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "#         all_translations.extend(decoded)\n",
    "\n",
    "#         # Free memory\n",
    "#         del inputs, translated, decoded\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     return all_translations\n",
    "    \n",
    "# all_translations = translate_sentences(source_sentences, baseline_model, baseline_tokenizer)\n",
    "# all_translations_custom = translate_sentences(source_sentences, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Translation function\n",
    "def translate_sentences_mbart(sentences, model, tokenizer, src_lang=\"fr_XX\", tgt_lang=\"en_XX\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Set the source language for the tokenizer\n",
    "    tokenizer.src_lang = src_lang\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch of sentences (with padding and truncation)\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "        \n",
    "        # Decode the generated tokens into readable text\n",
    "        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del inputs, generated_tokens, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "def translate_m2m_batch(sentences, model, tokenizer, src_lang=\"fr\", tgt_lang=\"en\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Get the target language ID\n",
    "    tgt_lang_id = tokenizer.get_lang_id(tgt_lang)\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "\n",
    "        # Tokenize the batch of sentences\n",
    "        encoded_input = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            translated = model.generate(\n",
    "                **encoded_input,\n",
    "                forced_bos_token_id=tgt_lang_id\n",
    "            )\n",
    "\n",
    "        # Decode the generated translations\n",
    "        decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del encoded_input, translated, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "all_translations = translate_sentences_mbart(source_sentences, model, tokenizer)\n",
    "all_translations_custom = translate_m2m_batch(source_sentences, model_m2m, tokenizer_m2m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu Score\n",
    "Exact word/phrase matching — how much of the machine translation is in direct alignment with the reference translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BLEU Score: 26.49\n",
      "Custom BLEU Score: 7.45\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Flatten the reference translations list (since it's a list of lists)\n",
    "references = [ref for ref in reference_translations]\n",
    "    \n",
    "# Calculate BLEU score for the baseline model\n",
    "bleu_custom = sacrebleu.corpus_bleu(all_translations_custom, [references], lowercase=True, tokenize='13a')\n",
    "bleu_baseline = sacrebleu.corpus_bleu(all_translations, [references], lowercase=True, tokenize='13a')\n",
    "\n",
    "print(f\"Baseline BLEU Score: {bleu_baseline.score:.2f}\")\n",
    "print(f\"Custom BLEU Score: {bleu_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TER Score\n",
    "Measures the number of edits (insertions, deletions, substitutions) needed to change the hypothesis into the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER for baseline: 63.72\n",
      "TER for custom: 97.96\n"
     ]
    }
   ],
   "source": [
    "ter_custom = sacrebleu.corpus_ter(all_translations_custom, [references])\n",
    "ter_score = sacrebleu.corpus_ter(all_translations, [references])\n",
    "\n",
    "print(f\"TER for baseline: {ter_score.score:.2f}\")\n",
    "print(f\"TER for custom: {ter_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChrF score\n",
    "Works better for languages with complex morphology.\n",
    "\n",
    "Can detect character-level errors (typos, word segmentation issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrF for baseline: 53.28\n",
      "ChrF for custom: 34.17\n"
     ]
    }
   ],
   "source": [
    "# ChrF (default settings, good for many languages)\n",
    "chrf_score = sacrebleu.corpus_chrf(all_translations, [references])\n",
    "chrf_custom = sacrebleu.corpus_chrf(all_translations_custom, [references])\n",
    "\n",
    "print(f\"ChrF for baseline: {chrf_score.score:.2f}\")\n",
    "print(f\"ChrF for custom: {chrf_custom.score:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE-L\n",
    "Captures content overlap, which makes it suitable for evaluation tasks where fluency and content preservation are crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg ROUGE-L for baseline: 53.85\n",
      "Avg ROUGE-L for custom: 25.64\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ROUGE-L (using rouge_score package)\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "rouge_l_scores = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations)]\n",
    "avg_rouge_l = 100 * sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "print(f\"Avg ROUGE-L for baseline: {avg_rouge_l:.2f}\")\n",
    "\n",
    "rouge_l_scores_custom = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations_custom)]\n",
    "avg_rouge_l_for_custom = 100 * sum(rouge_l_scores_custom) / len(rouge_l_scores_custom)\n",
    "\n",
    "print(f\"Avg ROUGE-L for custom: {avg_rouge_l_for_custom:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC   : L'inflation, en Europe, a dérapé sur l'alimentation\n",
      "REF   : Food: Where European inflation slipped up\n",
      "BASE  : Inflation in Europe has hit food\n",
      "CUSTOM: Inflation, in Europe, a depeat on food\n",
      "------------------------------------------------------------\n",
      "SRC   : L'inflation accélérée, mesurée dans la zone euro, est due principalement à l'augmentation rapide des prix de l'alimentation.\n",
      "REF   : The skyward zoom in food prices is the dominant force behind the speed up in eurozone inflation.\n",
      "BASE  : Increased inflation, measured in the euro area, is mainly due to the rapid rise in food prices.\n",
      "CUSTOM: The inflation accelerée, meurée dans la zone euro, est due mainly à l'augmentation rapide des prix de l'alimentation.\n",
      "------------------------------------------------------------\n",
      "SRC   : En novembre, l'augmentation des prix, dans les 13 pays de la zone euro, a été plus importante par rapport aux prévisions, après un taux d'inflation de 2,6 pour cent en octobre, une inflation annuelle de 3,1 pour cent a été enregistrée, a indiqué le bureau des statistiques de la Communauté Européenne situé à Luxembourg.\n",
      "REF   : November price hikes were higher than expected in the 13 eurozone countries, with October's 2.6 percent yr/yr inflation rate followed by 3.1 percent in November, the EU's Luxembourg-based statistical office reported.\n",
      "BASE  : In November, price increases in the 13 euro area countries were higher than expected, after an inflation rate of 2.6 per cent in October, annual inflation of 3.1 per cent was recorded, the European Community Statistics Office in Luxembourg reported.\n",
      "CUSTOM: In November, the increase des prix, dans les 13 pays de la zone euro, a été plus important par rapport aux prévisions, après un taux d'inflation de 2,6 pour cent en octobre, une inflation annuelle de 3,1 pour cent a été enregistrée, a indicqué le bureau des statistiques de la Communauté Européenne situé à Luxembourg.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les prévisions officielles n'ont indiqué que 3 pour cent, a communiqué Bloomberg.\n",
      "REF   : Official forecasts predicted just 3 percent, Bloomberg said.\n",
      "BASE  : Official forecasts indicated only 3 percent, Bloomberg reported.\n",
      "CUSTOM: Les prévisions officielles n'ont indiqué que 3 pour cent, a Bloomberg statement.\n",
      "------------------------------------------------------------\n",
      "SRC   : Contrairement aux banques centrales américaine, britannique et canadienne, la Banque centrale européenne (BCE) n'a pas baissé le taux d'intérêt directeur en disant que la diminution des intérêts, avec la croissance des prix des matières premières et la baisse du taux de chômage, conduirait à la génération d'une spirale inflationniste.\n",
      "REF   : As opposed to the US, UK, and Canadian central banks, the European Central Bank (ECB) did not cut interest rates, arguing that a rate drop combined with rising raw material prices and declining unemployment would trigger an inflationary spiral.\n",
      "BASE  : Unlike the U.S., UK, and Canadian central banks, the European Central Bank (ECB) did not lower the guide interest rate by saying that lower interest rates, along with higher commodity prices and lower unemployment rates, would lead to an inflationary spiral.\n",
      "CUSTOM: Contrary to the banques centrales americaine, britannique et canadienne, la Banque centrale européenne (BCE) n'a pas baissé le taux d'intérêt directeur en disant que la diminution des intérêts, avec la croissance des prix des matières premières et la baisse du taux de chômage, conduirait à la génération d'une spirale inflationniste.\n",
      "------------------------------------------------------------\n",
      "SRC   : La BCE souhaiterait maintenir le taux d'inflation au-dessous mais proche de deux pour cent.\n",
      "REF   : The ECB wants to hold inflation to under two percent, or somewhere in that vicinity.\n",
      "BASE  : The ECB would like to keep the inflation rate below but close to 2%.\n",
      "CUSTOM: The ECB would wish to maintain the inflation rate below but close to two per cent.\n",
      "------------------------------------------------------------\n",
      "SRC   : Selon un analyste, c'est le Catch 22 pour la BCE: \"il faut dissuader\" l'inflation afin de ne plus avoir à intervenir sur ce sujet ultérieurement.\n",
      "REF   : According to one analyst, ECB has been caught in a Catch-22: It needs to \"talk down\" inflation, to keep from having to take action to push it down later in the game.\n",
      "BASE  : According to one analyst, this is Catch 22 for the ECB: 'inflation must be deterred' so that we will no longer have to intervene on this subject in the future.\n",
      "CUSTOM: According to an analyst, it is le Catch 22 pour la BCE: \"il faut dissuader\" l'inflation afin de ne plus avoir à intervenir sur ce sujet ultérieurement.\n",
      "------------------------------------------------------------\n",
      "SRC   : En Allemagne, le taux d'inflation de 3,3 pour cent est un record au cours de ces douze dernières années et en Espagne, il est remonté de 3,6 à 4,1.\n",
      "REF   : Germany's November inflation rate of 3.3 percent counts as a record; in Spain the rate shot up to 4.1 percent from an earlier 3.6.\n",
      "BASE  : In Germany, the inflation rate of 3.3 per cent is a record in the past 12 years, and in Spain it has risen from 3.6 to 4.1.\n",
      "CUSTOM: In Germany, le taux d'inflation de 3,3 pour cent est un record au cours de ces douze dernières années et en Espagne, il est remonté de 3,6 à 4,1.\n",
      "------------------------------------------------------------\n",
      "SRC   : L'inflation dans la zone euro a décollé à cause de l'augmentation rapide des prix de l'alimentation et de l'énergie.\n",
      "REF   : Soaring food and energy prices sent eurozone inflation into the stratosphere.\n",
      "BASE  : Inflation in the euro area has arisen as a result of the rapid rise in food and energy prices.\n",
      "CUSTOM: The inflation dans la zone euro a decollé à cause de l'augmentation rapide des prix de l'alimentation et de l'énergie.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les cotes du marché à terme des céréales ont augmenté de 88 pour cent et le cours du soja a atteint également sa valeur la plus élevée depuis 1973.\n",
      "REF   : Wheat futures were up by 88 percent and soybean prices were at their highest since 1973.\n",
      "BASE  : The futures market for cereals increased by 88 per cent and the price of soybean also reached its highest level since 1973.\n",
      "CUSTOM: Les cotes du marché à terme des céréales ont augmenté de 88 pour cent et le cours du soja a atteint aussi sa valeur la plus élevée depuis 1973.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le prix de l'huile alimentaire et des produits laitiers a également considérablement augmenté en 2007.\n",
      "REF   : Consumers also have had to pay significantly more for vegetable oils and dairy products in 2007.\n",
      "BASE  : The prices of food oil and dairy products also increased significantly in 2007.\n",
      "CUSTOM: Le prix de l'huile alimentaire et des produits laitiers a aussi considérablement augmenté in 2007.\n",
      "------------------------------------------------------------\n",
      "SRC   : Cette année, le prix mondial du pétrole a augmenté de 52 pour cent et, le mois dernier, un baril d'or noir coûtait presque 100 dollars.\n",
      "REF   : The world market price of crude oil shot up by 52 percent this year, with the black gold costing nearly 100 dollars a barrel last month.\n",
      "BASE  : This year, world oil prices rose by 52 per cent and last month, a barrel of black gold cost nearly $100.\n",
      "CUSTOM: This year, le prix mondial du pétrole a augmenté de 52 pour cent et, le mois dernier, a baril d'or noir coûtait almost 100 dollars.\n",
      "------------------------------------------------------------\n",
      "SRC   : Selon la BCE, en 2008, le taux d'inflation passera de 2,1, cette année, à 2,5 pour cent mais, en 2009, il baissera à 1,9.\n",
      "REF   : The ECB predicts that 2008 inflation will climb to 2.5 percent from the earlier 2.1, but will drop back to 1.9 percent in 2009.\n",
      "BASE  : According to the ECB, in 2008, the inflation rate will increase from 2.1 this year to 2.5 percent, but in 2009 it will fall to 1.9 percent.\n",
      "CUSTOM: According to the ECB, in 2008, le taux d'inflation passera de 2,1, cette année, à 2,5 pour cent mais, in 2009, il baissera à 1,9.\n",
      "------------------------------------------------------------\n",
      "SRC   : Selon les analystes, le taux d'inflation sur 12 mois reste autour des 3 pour cent, cependant, les 3 à 4 mois prochains, le taux moyen annuel sera de 2,1 pour cent.\n",
      "REF   : Analysts see the 12-month inflation rate as holding steady at about 3 percent over the next 3-4 months, but say that the annual average rate will be 2.1 percent.\n",
      "BASE  : According to analysts, the 12-month inflation rate remains around 3 per cent, but over the next 3 to 4 months the average annual rate will be 2.1 per cent.\n",
      "CUSTOM: According to analysts, le taux d'inflation sur 12 mois reste autour des 3 pour cent, cependant, les 3 à 4 mois prochains, le taux moyen annuel sera de 2,1 pour cent.\n",
      "------------------------------------------------------------\n",
      "SRC   : En même temps, ils s'attendent à ce que la BCE diminue le taux directeur deux fois en 2008.\n",
      "REF   : They also predict that the ECB will cut interest rates twice during the course of 2008.\n",
      "BASE  : At the same time, they expect the ECB to reduce the operating rate twice in 2008.\n",
      "CUSTOM: In the same time, they are expecting that the ECB decreases the rate directeur twice in 2008.\n",
      "------------------------------------------------------------\n",
      "SRC   : Gallup indique une crise du gouvernement\n",
      "REF   : Government crisis coming, says Gallup\n",
      "BASE  : Gallup signals government crisis\n",
      "CUSTOM: Gallup indicates a crisis of government\n",
      "------------------------------------------------------------\n",
      "SRC   : Après une longue stagnation, le nombre des partisans du Fidesz (Alliance des jeunes démocrates) a augmenté significativement début décembre. Ainsi depuis 2002, il dispose actuellement du plus grand nombre de partisans, alors que Gallup (Institut de sondage) n'a jamais constaté auparavant un aussi faible soutien socialiste, à savoir 13 pour cent.\n",
      "REF   : Fidesz support shot up significantly in early December after a lengthy period of just holding its own. This gives it the strongest support base it has seen since 2002, while Gallup reports support for the socialists at an all-time low of 13 percent.\n",
      "BASE  : After a long stagnation, the number of Fidesz (Youth Democratic Alliance) supporters increased significantly in early December, with the largest number of supporters since 2002, while Gallup (Institute for Surveying) has never seen such a low level of Socialist support, namely 13%.\n",
      "CUSTOM: After a long stagnation, le nombre des partisans du Fidesz (Alliance des jeunes démocrates) a augmenté significativement début décembre. Ainsi since 2002, il dispose actuellement du plus grand nombre de partisans, alors que Gallup (Institut de sondage) n'a jamais constaté auparavant un aussi faible soutien socialiste, à savoir 13 per cent.\n",
      "------------------------------------------------------------\n",
      "SRC   : Pour les électeurs fidèles, la différence représenterait, en raison de la plus grande détermination des électeurs de l'opposition, un soutien de plus de deux tiers (71 pour cent) contre le soutien d'un cinquième (20 pour cent) pour le MSZP (Parti socialiste hongrois).\n",
      "REF   : Among people with a clear party preference, given the stronger resolve of opposition voters, Fidesz support exceeds the two-thirds mark (71 percent), while MSZP has garnered but one-fifth (20 percent).\n",
      "BASE  : For the faithful voters, the difference would be more than two-thirds (71 per cent) support, due to the strongest determination of the opposition voters, versus a fifth (20 per cent) support for the MSZP (Hungarian Socialist Party).\n",
      "CUSTOM: Pour les électeurs fidèles, la différence représenterait, en raison de la plus grande détermination des électeurs de l'opposition, un soutien de plus de deux tiers (71 per cent) contre le soutien d'un cinquième (20 per cent) pour le MSZP (Parti socialiste hongrois).\n",
      "------------------------------------------------------------\n",
      "SRC   : Selon le sondage, le MDF (Forum des démocrates hongrois) et le SZDSZ (Alliance des démocrates libres) sont au-dessous du seuil de parlementaires: leur soutien est de deux pour cent dans toute la population.\n",
      "REF   : The poll puts MDF and SZDSZ numbers below the threshold needed to get into parliament; garnering about 2 percent support each within the entire sample.\n",
      "BASE  : According to the survey, the MDF (Forum of Hungarian Democrats) and the SZDSZ (Alliance of Free Democrats) are below the parliamentary threshold: their support is two per cent in the whole population.\n",
      "CUSTOM: According to the sondage, the MDF (Forum des démocrates hongrois) and the SZDSZ (Alliance des démocrates libres) are au-dessous du seuil de parlementaires: leur soutien est de deux pour cent dans toute la population.\n",
      "------------------------------------------------------------\n",
      "SRC   : Sur les électeurs fidèles certains d'aller voter, le nombre des partisans des deux partis a augmenté de 1 pour cent.\n",
      "REF   : Among people with clear party preferences who say they definitely would vote, support for these two parties is 3 percent each.\n",
      "BASE  : Among the faithful voters who are going to vote, the number of supporters of both parties has increased by 1 per cent.\n",
      "CUSTOM: Sur les électeurs fidèles certains d'aller voter, le nombre des partisans des deux partis a augmenté de 1 pour cent.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(source_sentences)):\n",
    "    print(f\"SRC   : {source_sentences[i]}\")\n",
    "    print(f\"REF   : {reference_translations[i]}\")\n",
    "    print(f\"BASE  : {all_translations[i]}\")\n",
    "    print(f\"CUSTOM: {all_translations_custom[i]}\")\n",
    "    # print(f\"Facebook: {all_translations_facebook[i]}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Optional: limit output (e.g., to first 20 examples)\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test_set 4 (newstest2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Au terme des échanges, la bourse de Prague bas...</td>\n",
       "      <td>Prague Stock Market falls to minus by the end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Après la chute de mardi matin, la bourse de Pr...</td>\n",
       "      <td>After a sharp drop in the morning, the Prague ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Les transactions avec les actions ČEZ atteigni...</td>\n",
       "      <td>Transactions with stocks from the Czech Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mardi, dès le début des échanges, la bourse de...</td>\n",
       "      <td>The Prague Stock Market immediately continued ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cette fois-ci, la baisse est due à la chute de...</td>\n",
       "      <td>This time the fall in stocks on Wall Street is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Verdant a annoncé avoir une longue liste de cl...</td>\n",
       "      <td>Verdant has said that it has a long list of cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>Après les vagues, les marées.</td>\n",
       "      <td>After the waves, the tides.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>Un intérêt particulier, disent-ils à l'Institu...</td>\n",
       "      <td>Particular interest, declare the people at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>Bien qu'il s'agisse d'un phénomène intermitten...</td>\n",
       "      <td>Even though it is an intermittent phenomenon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>Et c'est justement sur l'énergie des marées qu...</td>\n",
       "      <td>It's exactly on tidal energy that states such ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2525 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 french  \\\n",
       "0     Au terme des échanges, la bourse de Prague bas...   \n",
       "1     Après la chute de mardi matin, la bourse de Pr...   \n",
       "2     Les transactions avec les actions ČEZ atteigni...   \n",
       "3     Mardi, dès le début des échanges, la bourse de...   \n",
       "4     Cette fois-ci, la baisse est due à la chute de...   \n",
       "...                                                 ...   \n",
       "2520  Verdant a annoncé avoir une longue liste de cl...   \n",
       "2521                      Après les vagues, les marées.   \n",
       "2522  Un intérêt particulier, disent-ils à l'Institu...   \n",
       "2523  Bien qu'il s'agisse d'un phénomène intermitten...   \n",
       "2524  Et c'est justement sur l'énergie des marées qu...   \n",
       "\n",
       "                                                english  \n",
       "0     Prague Stock Market falls to minus by the end ...  \n",
       "1     After a sharp drop in the morning, the Prague ...  \n",
       "2     Transactions with stocks from the Czech Energy...  \n",
       "3     The Prague Stock Market immediately continued ...  \n",
       "4     This time the fall in stocks on Wall Street is...  \n",
       "...                                                 ...  \n",
       "2520  Verdant has said that it has a long list of cl...  \n",
       "2521                        After the waves, the tides.  \n",
       "2522  Particular interest, declare the people at the...  \n",
       "2523  Even though it is an intermittent phenomenon, ...  \n",
       "2524  It's exactly on tidal energy that states such ...  \n",
       "\n",
       "[2525 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the French file\n",
    "with open('testing_dataset/newstest2009.fr', 'r', encoding='utf-8') as f_fr:\n",
    "    french_sentences = [line.strip() for line in f_fr]\n",
    "\n",
    "# Read the aligned English file\n",
    "with open('testing_dataset/newstest2009.en', 'r', encoding='utf-8') as f_en:\n",
    "    english_sentences = [line.strip() for line in f_en]\n",
    "\n",
    "# Make sure both have the same number of lines\n",
    "assert len(french_sentences) == len(english_sentences), \"Files are not aligned!\"\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'french': french_sentences,\n",
    "    'english': english_sentences\n",
    "})\n",
    "\n",
    "# Optional: Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Preview\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences = dataset['french']\n",
    "reference_translations = dataset['english']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import sacrebleu\n",
    "\n",
    "# def translate_sentences(sentences, model, tokenizer, batch_size=16):\n",
    "#     model.eval()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "\n",
    "#     all_translations = []\n",
    "\n",
    "#     for i in range(0, len(sentences), batch_size):\n",
    "#         batch = sentences[i:i+batch_size]\n",
    "#         inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             translated = model.generate(**inputs, max_length=512)\n",
    "#         decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "#         all_translations.extend(decoded)\n",
    "\n",
    "#         # Free memory\n",
    "#         del inputs, translated, decoded\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     return all_translations\n",
    "    \n",
    "# all_translations = translate_sentences(source_sentences, baseline_model, baseline_tokenizer)\n",
    "# all_translations_custom = translate_sentences(source_sentences, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Translation function\n",
    "def translate_sentences_mbart(sentences, model, tokenizer, src_lang=\"fr_XX\", tgt_lang=\"en_XX\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Set the source language for the tokenizer\n",
    "    tokenizer.src_lang = src_lang\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch of sentences (with padding and truncation)\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "        \n",
    "        # Decode the generated tokens into readable text\n",
    "        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del inputs, generated_tokens, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "def translate_m2m_batch(sentences, model, tokenizer, src_lang=\"fr\", tgt_lang=\"en\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Get the target language ID\n",
    "    tgt_lang_id = tokenizer.get_lang_id(tgt_lang)\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "\n",
    "        # Tokenize the batch of sentences\n",
    "        encoded_input = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            translated = model.generate(\n",
    "                **encoded_input,\n",
    "                forced_bos_token_id=tgt_lang_id\n",
    "            )\n",
    "\n",
    "        # Decode the generated translations\n",
    "        decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del encoded_input, translated, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "all_translations = translate_sentences_mbart(source_sentences, model, tokenizer)\n",
    "all_translations_custom = translate_m2m_batch(source_sentences, model_m2m, tokenizer_m2m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu Score\n",
    "Exact word/phrase matching — how much of the machine translation is in direct alignment with the reference translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BLEU Score: 30.30\n",
      "Custom BLEU Score: 8.14\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Flatten the reference translations list (since it's a list of lists)\n",
    "references = [ref for ref in reference_translations]\n",
    "    \n",
    "# Calculate BLEU score for the baseline model\n",
    "bleu_custom = sacrebleu.corpus_bleu(all_translations_custom, [references], lowercase=True, tokenize='13a')\n",
    "bleu_baseline = sacrebleu.corpus_bleu(all_translations, [references], lowercase=True, tokenize='13a')\n",
    "\n",
    "print(f\"Baseline BLEU Score: {bleu_baseline.score:.2f}\")\n",
    "print(f\"Custom BLEU Score: {bleu_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TER Score\n",
    "Measures the number of edits (insertions, deletions, substitutions) needed to change the hypothesis into the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER for baseline: 58.73\n",
      "TER for custom: 94.97\n"
     ]
    }
   ],
   "source": [
    "ter_custom = sacrebleu.corpus_ter(all_translations_custom, [references])\n",
    "ter_score = sacrebleu.corpus_ter(all_translations, [references])\n",
    "\n",
    "print(f\"TER for baseline: {ter_score.score:.2f}\")\n",
    "print(f\"TER for custom: {ter_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChrF score\n",
    "Works better for languages with complex morphology.\n",
    "\n",
    "Can detect character-level errors (typos, word segmentation issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrF for baseline: 55.83\n",
      "ChrF for custom: 34.65\n"
     ]
    }
   ],
   "source": [
    "# ChrF (default settings, good for many languages)\n",
    "chrf_score = sacrebleu.corpus_chrf(all_translations, [references])\n",
    "chrf_custom = sacrebleu.corpus_chrf(all_translations_custom, [references])\n",
    "\n",
    "print(f\"ChrF for baseline: {chrf_score.score:.2f}\")\n",
    "print(f\"ChrF for custom: {chrf_custom.score:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE-L\n",
    "Captures content overlap, which makes it suitable for evaluation tasks where fluency and content preservation are crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg ROUGE-L for baseline: 57.49\n",
      "Avg ROUGE-L for custom: 25.65\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ROUGE-L (using rouge_score package)\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "rouge_l_scores = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations)]\n",
    "avg_rouge_l = 100 * sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "print(f\"Avg ROUGE-L for baseline: {avg_rouge_l:.2f}\")\n",
    "\n",
    "rouge_l_scores_custom = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations_custom)]\n",
    "avg_rouge_l_for_custom = 100 * sum(rouge_l_scores_custom) / len(rouge_l_scores_custom)\n",
    "\n",
    "print(f\"Avg ROUGE-L for custom: {avg_rouge_l_for_custom:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC   : Au terme des échanges, la bourse de Prague bascula dans le négatif\n",
      "REF   : Prague Stock Market falls to minus by the end of the trading day\n",
      "BASE  : At the end of the exchanges, the Prague Stock Exchange is down in the negative\n",
      "CUSTOM: Au terme des échanges, la bourse de Prague bascula dans le négatif\n",
      "------------------------------------------------------------\n",
      "SRC   : Après la chute de mardi matin, la bourse de Prague réctifia ses pertes.\n",
      "REF   : After a sharp drop in the morning, the Prague Stock Market corrected its losses.\n",
      "BASE  : After the fall of Tuesday morning, the Prague Stock Exchange corrected its losses.\n",
      "CUSTOM: After the fall of Tuesday morning, the bourse of Prague rectifia ses pertes.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les transactions avec les actions ČEZ atteignirent presque la moitié des échanges quotidiens habituels.\n",
      "REF   : Transactions with stocks from the Czech Energy Enterprise (ČEZ) reached nearly half of the regular daily trading.\n",
      "BASE  : Transactions with ČEZ shares accounted for almost half of regular daily exchanges.\n",
      "CUSTOM: The transactions with the actions of ČEZ atteignirent almost the moitié des échanges daily usual.\n",
      "------------------------------------------------------------\n",
      "SRC   : Mardi, dès le début des échanges, la bourse de Prague renoua avec sa chute de la veille, lorsqu'elle perdait presque six pour cent.\n",
      "REF   : The Prague Stock Market immediately continued its fall from Monday at the beginning of Tuesday's trading, when it dropped by nearly six percent.\n",
      "BASE  : On Tuesday, at the beginning of trading, the Prague stock exchange resumed with its fall the day before, when it lost almost six percent.\n",
      "CUSTOM: Mardi, dès le début des échanges, la bourse de Prague renoua avec sa chute de la veille, lorsqu'elle perdait quasi six pour cent.\n",
      "------------------------------------------------------------\n",
      "SRC   : Cette fois-ci, la baisse est due à la chute des actions au Wall Street.\n",
      "REF   : This time the fall in stocks on Wall Street is responsible for the drop.\n",
      "BASE  : This time, the decline is due to the fall in shares on Wall Street.\n",
      "CUSTOM: This time, la baisse est due à la chute des actions au Wall Street.\n",
      "------------------------------------------------------------\n",
      "SRC   : La réaction du marché face au résultat du vote de la Chambre des représentants américaine, qui refusa d'adopter le plan de stabilisation du secteur financier américain, est ainsi perceptible également chez nous.\n",
      "REF   : The reaction of the market to the results of the vote in the American House of Representatives, which refused to support the plan for the stabilization of the financial sector there, has manifested itself here as well.\n",
      "BASE  : The reaction of the market to the outcome of the vote in the United States House of Representatives, which refused to adopt the US financial sector stabilisation plan, is thus also perceptible in our own country.\n",
      "CUSTOM: The reaction of the market face to the result of the vote of the Chambre des représentants américaine, which refuses to adopt the plan of stabilisation of the sector financier américain, is thus perceived also at us.\n",
      "------------------------------------------------------------\n",
      "SRC   : Chute des actions en Asie\n",
      "REF   : Stocks fall in Asia\n",
      "BASE  : The fall in shares in Asia\n",
      "CUSTOM: Chute des actions in Asia\n",
      "------------------------------------------------------------\n",
      "SRC   : Les bourses asiatiques vécurent mardi une chute dramatique, même si les indices réussirent, au cours de la journée, d'effacer une partie des pertes.\n",
      "REF   : Stocks in the Asian markets experienced a dramatic drop on Tuesday, even though the indexes ultimately erased a part of the losses during the day.\n",
      "BASE  : Asian stock exchanges suffered a dramatic downturn Tuesday, even though indices managed to eliminate some of the losses during the day.\n",
      "CUSTOM: Les bourses asiatiques vécurent mardi une chute dramatique, même si les indices réussirent, au cours de la journée, d'effacer une partie des pertes.\n",
      "------------------------------------------------------------\n",
      "SRC   : L'indice Hang Seng de la bourse de Hongkong perdit quatre pour cent pendant les échanges, mais plus tard, il effaça une partie des pertes et réduit la baisse à près de 2,5 pour cent.\n",
      "REF   : The Hang Seng Index of the Hong Kong Stock Exchange wrote off nearly four percent during the day, but later it erased a part of the losses and reduced the decrease to roughly 2.5 percent.\n",
      "BASE  : The Hang Seng index of the Hong Kong Stock Exchange lost four percent during trading, but later reduced some of the losses and reduced the decline to almost 2.5 percent.\n",
      "CUSTOM: The index Hang Seng de la bourse de Hong Kong perits four per cent during the exchanges, but plus later, il effaça une partie des pertes et réduit la baisse à près de 2,5 per cent.\n",
      "------------------------------------------------------------\n",
      "SRC   : L'indice Hang Seng China Enterprises suivant le mouvement des actions chinoises de la bourse de Hongkong perdit 3,8 pour cent, les marchés étant clos à Shanghaï.\n",
      "REF   : The Hang Seng China Enterprises Index, which follows the movement of Chinese stocks on the stock market in Hong Kong, dropped by 3.8 percent, in Shanghai the markets were closed.\n",
      "BASE  : The Hang Seng China Enterprises index, following the movement of Chinese shares on the Hong Kong Stock Exchange, lost 3.8 per cent, with markets closed in Shanghai.\n",
      "CUSTOM: The index Hang Seng China Enterprises following le mouvement des actions chinoises de la bourse de Hong Kong perits 3.8 per cent, les marchés étant clos à Shanghaï.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les actions de la bourse de Sydney perdaient plus de cinq pour cent, mais finalement on réussit à réduire les pertes à 4,3 pour cent.\n",
      "REF   : Stocks on the market in Sydney lost more than five percent, but ultimately lowered their losses to 4.3 percent.\n",
      "BASE  : Shares on the Sydney Stock Exchange lost more than five percent, but eventually the losses were reduced to 4.3 percent.\n",
      "CUSTOM: The actions de la bourse de Sydney perdia plus de cinq pour cent, but ultimately on réussit à réduire les pertes à 4,3 pour cent.\n",
      "------------------------------------------------------------\n",
      "SRC   : Selon son indice, la Bourse de Taiwan perdit 3,6 pour cent.\n",
      "REF   : The stock exchange in Taiwan dropped by 3.6 percent according to the local index.\n",
      "BASE  : According to its index, the Taiwan Stock Exchange loses 3.6 per cent.\n",
      "CUSTOM: According to son index, la Bourse de Taiwan lost 3.6 percent.\n",
      "------------------------------------------------------------\n",
      "SRC   : \"L'hésitation au sujet de l'action de sauvetage aux USA influera sur les marchés financiers du monde entier,\" observa Joseph Yam, le chef de l'office monétaire de Hongkong.\n",
      "REF   : \"The timing of the bailout action in the USA is uncertain and it will influence financial markets all over the world,\" remarked the head of the Hong Kong Currency Board, Joseph Yam.\n",
      "BASE  : \"The hesitation about rescue action in the US will affect financial markets around the world,\" said Joseph Yam, head of the Hong Kong Monetary Office.\n",
      "CUSTOM: “The hesitation au sujet de l’action de sauvetage aux USA influences on les marchés financiers du monde entier,” observes Joseph Yam, le chef de l’office monétaire de Hong Kong.\n",
      "------------------------------------------------------------\n",
      "SRC   : Bien que Hongkong fasse partie de la Chine, il établit sa politique monétaire lui-même, c'est-à-dire indépendamment de la banque centrale chinoise.\n",
      "REF   : Despite the fact that it is a part of China, Hong Kong determines its currency policy separately, that is, without being dependent on the Chinese Central Bank.\n",
      "BASE  : Although Hong Kong is part of China, it sets its own monetary policy, that is, independently of the Chinese central bank.\n",
      "CUSTOM: Bien que Hong Kong fasse partie de la China, il établit sa politique monetaire lui-même, c'est-à-dire independently de la banque centrale chinoise.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les taux d'intérêt ont à Hongkong le même niveau qu'aux Etats-Unis.\n",
      "REF   : Hong Kong has interest rates at the same level as the United States.\n",
      "BASE  : Interest rates in Hong Kong are the same as in the United States.\n",
      "CUSTOM: Les taux d'intérêt ont à Hong Kong le même niveau qu'aux USA.\n",
      "------------------------------------------------------------\n",
      "SRC   : Selon le premier ministre australien Kevin Rudd, les législateurs américains devraient vite reprendre les négociations et adopter la proposition de soutient du système financier.\n",
      "REF   : American legislators should quickly return to their negotiations and approve the bill to support the financial system, according to Australian Prime Minister Kevin Rudd.\n",
      "BASE  : According to Australian Prime Minister Kevin Rudd, US legislators should quickly resume negotiations and adopt the proposal to support the financial system.\n",
      "CUSTOM: According to Australian Prime Minister Kevin Rudd, the US legislators should vite reprendre les négociations and adopt the proposition de soutient du système financier.\n",
      "------------------------------------------------------------\n",
      "SRC   : Autrement, on risquerait que d'autres pays en subissent les incidences.\n",
      "REF   : Otherwise there reputedly looms the threat that other countries will also feel the impacts.\n",
      "BASE  : Otherwise, there would be a risk that other countries would be affected.\n",
      "CUSTOM: Autrement, on risquerait that others pay in subissent les incidences.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le bain de sang des actions américaines\n",
      "REF   : American stock bloodbath\n",
      "BASE  : The bloodbath of American action\n",
      "CUSTOM: Le bain de sang des actions américaines\n",
      "------------------------------------------------------------\n",
      "SRC   : Lundi, la Chambre des représentants américaine rejeta le projet de soutient du système financier, auquel elle aurait dû consacrer jusqu'à 700 milliards de dollars (près de 12 bilions de Kč).\n",
      "REF   : On Monday the American House of Representatives rejected the plan to support the financial system, into which up to 700 billion dollars (nearly 12 billion Czech crowns) was to be invested.\n",
      "BASE  : On Monday, the U.S. House of Representatives rejected the project to support the financial system, to which it should have devoted up to $700 billion (nearly CZK 12 trillion).\n",
      "CUSTOM: On Monday, the Chambre des représentants américaine rejeta le projet de soutient du système financier, auquel elle aurait dû consacrer jusqu'à 700 billion de dollars (près de 12 billion de Kč).\n",
      "------------------------------------------------------------\n",
      "SRC   : Les législateurs renièrent ainsi l'appel au soutient du projet du président George Bush.\n",
      "REF   : The legislators thus ignored President George Bush's appeal for them to support the plan.\n",
      "BASE  : Legislators thus rejected the call for support for President George Bush's proposal.\n",
      "CUSTOM: Les législateurs renièrent ainsi l'appel au soutient du projet du président George Bush.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(source_sentences)):\n",
    "    print(f\"SRC   : {source_sentences[i]}\")\n",
    "    print(f\"REF   : {reference_translations[i]}\")\n",
    "    print(f\"BASE  : {all_translations[i]}\")\n",
    "    print(f\"CUSTOM: {all_translations_custom[i]}\")\n",
    "    # print(f\"Facebook: {all_translations_facebook[i]}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Optional: limit output (e.g., to first 20 examples)\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test_set 5 (newstest2014-fren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spectaculaire saut en \"wingsuit\" au-dessus de ...</td>\n",
       "      <td>Spectacular Wingsuit Jump Over Bogota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le sportif Jhonathan Florez a sauté jeudi d'un...</td>\n",
       "      <td>Sportsman Jhonathan Florez jumped from a helic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Equipé d'un wingsuit (une combinaison munie d'...</td>\n",
       "      <td>Wearing a wingsuit, he flew past over the famo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Une boîte noire dans votre voiture ?</td>\n",
       "      <td>A black box in your car?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alors que les planificateurs du réseau routier...</td>\n",
       "      <td>As America's road planners struggle to find th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>La commission scolaire Marguerite-Bourgeoys a ...</td>\n",
       "      <td>The Marguerite-Bourgeoys School Board has crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Rachida Azdouz, de l'Université de Montréal, e...</td>\n",
       "      <td>Rachida Azdouz from the University of Montreal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>La préparation à gérer une classe dans un cont...</td>\n",
       "      <td>Preparation to manage a class in a North-Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>\"Des stratégies pédagogiques différentes, c'es...</td>\n",
       "      <td>\"The real need is for different educational st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>Les recherches porteront sur l'inclusion sous ...</td>\n",
       "      <td>The research will address inclusion from every...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 french  \\\n",
       "0     Spectaculaire saut en \"wingsuit\" au-dessus de ...   \n",
       "1     Le sportif Jhonathan Florez a sauté jeudi d'un...   \n",
       "2     Equipé d'un wingsuit (une combinaison munie d'...   \n",
       "3                  Une boîte noire dans votre voiture ?   \n",
       "4     Alors que les planificateurs du réseau routier...   \n",
       "...                                                 ...   \n",
       "2998  La commission scolaire Marguerite-Bourgeoys a ...   \n",
       "2999  Rachida Azdouz, de l'Université de Montréal, e...   \n",
       "3000  La préparation à gérer une classe dans un cont...   \n",
       "3001  \"Des stratégies pédagogiques différentes, c'es...   \n",
       "3002  Les recherches porteront sur l'inclusion sous ...   \n",
       "\n",
       "                                                english  \n",
       "0                 Spectacular Wingsuit Jump Over Bogota  \n",
       "1     Sportsman Jhonathan Florez jumped from a helic...  \n",
       "2     Wearing a wingsuit, he flew past over the famo...  \n",
       "3                              A black box in your car?  \n",
       "4     As America's road planners struggle to find th...  \n",
       "...                                                 ...  \n",
       "2998  The Marguerite-Bourgeoys School Board has crea...  \n",
       "2999  Rachida Azdouz from the University of Montreal...  \n",
       "3000  Preparation to manage a class in a North-Ameri...  \n",
       "3001  \"The real need is for different educational st...  \n",
       "3002  The research will address inclusion from every...  \n",
       "\n",
       "[3003 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the French file\n",
    "with open('testing_dataset/newstest2014-fren.fr', 'r', encoding='utf-8') as f_fr:\n",
    "    french_sentences = [line.strip() for line in f_fr]\n",
    "\n",
    "# Read the aligned English file\n",
    "with open('testing_dataset/newstest2014-fren.en', 'r', encoding='utf-8') as f_en:\n",
    "    english_sentences = [line.strip() for line in f_en]\n",
    "\n",
    "# Make sure both have the same number of lines\n",
    "assert len(french_sentences) == len(english_sentences), \"Files are not aligned!\"\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'french': french_sentences,\n",
    "    'english': english_sentences\n",
    "})\n",
    "\n",
    "# Optional: Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Preview\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sentences = dataset['french']\n",
    "reference_translations = dataset['english']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import sacrebleu\n",
    "\n",
    "# def translate_sentences(sentences, model, tokenizer, batch_size=16):\n",
    "#     model.eval()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "\n",
    "#     all_translations = []\n",
    "\n",
    "#     for i in range(0, len(sentences), batch_size):\n",
    "#         batch = sentences[i:i+batch_size]\n",
    "#         inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             translated = model.generate(**inputs, max_length=512)\n",
    "#         decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "#         all_translations.extend(decoded)\n",
    "\n",
    "#         # Free memory\n",
    "#         del inputs, translated, decoded\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     return all_translations\n",
    "    \n",
    "# all_translations = translate_sentences(source_sentences, baseline_model, baseline_tokenizer)\n",
    "# all_translations_custom = translate_sentences(source_sentences, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Translation function\n",
    "def translate_sentences_mbart(sentences, model, tokenizer, src_lang=\"fr_XX\", tgt_lang=\"en_XX\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Set the source language for the tokenizer\n",
    "    tokenizer.src_lang = src_lang\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch of sentences (with padding and truncation)\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "        \n",
    "        # Decode the generated tokens into readable text\n",
    "        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del inputs, generated_tokens, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "def translate_m2m_batch(sentences, model, tokenizer, src_lang=\"fr\", tgt_lang=\"en\", batch_size=16):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_translations = []\n",
    "\n",
    "    # Get the target language ID\n",
    "    tgt_lang_id = tokenizer.get_lang_id(tgt_lang)\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "\n",
    "        # Tokenize the batch of sentences\n",
    "        encoded_input = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "        # Generate translations\n",
    "        with torch.no_grad():\n",
    "            translated = model.generate(\n",
    "                **encoded_input,\n",
    "                forced_bos_token_id=tgt_lang_id\n",
    "            )\n",
    "\n",
    "        # Decode the generated translations\n",
    "        decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "        all_translations.extend(decoded)\n",
    "\n",
    "        # Clear memory (optional)\n",
    "        del encoded_input, translated, decoded\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return all_translations\n",
    "all_translations = translate_sentences_mbart(source_sentences, model, tokenizer)\n",
    "all_translations_custom = translate_m2m_batch(source_sentences, model_m2m, tokenizer_m2m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu Score\n",
    "Exact word/phrase matching — how much of the machine translation is in direct alignment with the reference translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline BLEU Score: 37.79\n",
      "Custom BLEU Score: 8.37\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# Flatten the reference translations list (since it's a list of lists)\n",
    "references = [ref for ref in reference_translations]\n",
    "    \n",
    "# Calculate BLEU score for the baseline model\n",
    "bleu_custom = sacrebleu.corpus_bleu(all_translations_custom, [references], lowercase=True, tokenize='13a')\n",
    "bleu_baseline = sacrebleu.corpus_bleu(all_translations, [references], lowercase=True, tokenize='13a')\n",
    "\n",
    "print(f\"Baseline BLEU Score: {bleu_baseline.score:.2f}\")\n",
    "print(f\"Custom BLEU Score: {bleu_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TER Score\n",
    "Measures the number of edits (insertions, deletions, substitutions) needed to change the hypothesis into the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER for baseline: 49.47\n",
      "TER for custom: 96.79\n"
     ]
    }
   ],
   "source": [
    "ter_custom = sacrebleu.corpus_ter(all_translations_custom, [references])\n",
    "ter_score = sacrebleu.corpus_ter(all_translations, [references])\n",
    "\n",
    "print(f\"TER for baseline: {ter_score.score:.2f}\")\n",
    "print(f\"TER for custom: {ter_custom.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChrF score\n",
    "Works better for languages with complex morphology.\n",
    "\n",
    "Can detect character-level errors (typos, word segmentation issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrF for baseline: 61.95\n",
      "ChrF for custom: 35.75\n"
     ]
    }
   ],
   "source": [
    "# ChrF (default settings, good for many languages)\n",
    "chrf_score = sacrebleu.corpus_chrf(all_translations, [references])\n",
    "chrf_custom = sacrebleu.corpus_chrf(all_translations_custom, [references])\n",
    "\n",
    "print(f\"ChrF for baseline: {chrf_score.score:.2f}\")\n",
    "print(f\"ChrF for custom: {chrf_custom.score:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE-L\n",
    "Captures content overlap, which makes it suitable for evaluation tasks where fluency and content preservation are crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg ROUGE-L for baseline: 64.88\n",
      "Avg ROUGE-L for custom: 27.76\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ROUGE-L (using rouge_score package)\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "rouge_l_scores = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations)]\n",
    "avg_rouge_l = 100 * sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "print(f\"Avg ROUGE-L for baseline: {avg_rouge_l:.2f}\")\n",
    "\n",
    "rouge_l_scores_custom = [scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, all_translations_custom)]\n",
    "avg_rouge_l_for_custom = 100 * sum(rouge_l_scores_custom) / len(rouge_l_scores_custom)\n",
    "\n",
    "print(f\"Avg ROUGE-L for custom: {avg_rouge_l_for_custom:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC   : Spectaculaire saut en \"wingsuit\" au-dessus de Bogota\n",
      "REF   : Spectacular Wingsuit Jump Over Bogota\n",
      "BASE  : Spectacular \"wingsuit\" jump over Bogota\n",
      "CUSTOM: Spectaculaire saut in \"wingsuit\" au-dessus de Bogota\n",
      "------------------------------------------------------------\n",
      "SRC   : Le sportif Jhonathan Florez a sauté jeudi d'un hélicoptère au-dessus de Bogota, la capitale colombienne.\n",
      "REF   : Sportsman Jhonathan Florez jumped from a helicopter above Bogota, the capital of Colombia, on Thursday.\n",
      "BASE  : Athlete Jhonathan Florez jumped from a helicopter over Bogota, Colombia's capital, Thursday.\n",
      "CUSTOM: Jhonathan Florez a sauté jeudi d'un hélicoptère au-dessus de Bogota, la capitale colombienne.\n",
      "------------------------------------------------------------\n",
      "SRC   : Equipé d'un wingsuit (une combinaison munie d'ailes), il est passé à 160 km/h au-dessus du célèbre sanctuaire Monserrate, situé à plus de 3 000 mètres d'altitude, où de nombreux badauds s'étaient rassemblés pour observer son exploit.\n",
      "REF   : Wearing a wingsuit, he flew past over the famous Monserrate Sanctuary at 160km/h. The sanctuary is located at an altitude of over 3000 meters and numerous spectators had gathered there to watch his exploit.\n",
      "BASE  : Equipped with a wingsuit (a pair of wingsuits), he flew at 160 km/h over the famous Monserrate sanctuary, more than 3,000 metres above sea level, where many badauds gathered to observe his performance.\n",
      "CUSTOM: Equipé d'un wingsuit (une combinaison munie d'ailes), il est passé à 160 km/h au-dessus du célèbre sanctuaire Monserrate, situé à plus de 3 000 m d'altitude, where de nombreux badauds s'étaient rassemblés pour observer son exploit.\n",
      "------------------------------------------------------------\n",
      "SRC   : Une boîte noire dans votre voiture ?\n",
      "REF   : A black box in your car?\n",
      "BASE  : A black box in your car?\n",
      "CUSTOM: One boîte noire in your car?\n",
      "------------------------------------------------------------\n",
      "SRC   : Alors que les planificateurs du réseau routier des États-Unis ont du mal à trouver l'argent nécessaire pour réparer l'infrastructure autoroutière en décrépitude, nombreux sont ceux qui entrevoient une solution sous forme d'une petite boîte noire qui se fixe au-dessus du tableau de bord de votre voiture.\n",
      "REF   : As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\n",
      "BASE  : While U.S. road planners struggle to find the money to repair the road infrastructure quickly, many are looking for a solution in the form of a small black box that sits on top of your car's dashboard.\n",
      "CUSTOM: While that the planificateurs du réseau routier des États-Unis ont du mal à trouver l'argent nécessaire pour réparer l'infrastructure autoroutière en décrépitude, nombreux sont ceux qui entrevoient une solution sous forme d'une petite boîte noire qui se fixe au-dessus du tableau de bord de votre voiture.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les appareils, qui enregistrent tous les miles parcourus par un automobiliste et transmettent les informations aux fonctionnaires, sont au centre d'une tentative controversée à Washington et dans les bureaux gouvernementaux de la planification de remanier le système obsolète de financement des principales routes américaines.\n",
      "REF   : The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\n",
      "BASE  : The aircraft, which record all the miles travelled by a driver and transmit information to officials, are at the centre of a controversial attempt in Washington and in government planning offices to overhaul the outdated system for financing major U.S. roads.\n",
      "CUSTOM: “Les appareils, qui enregistrent tous les miles parcourus par un automobiliste et transmettent les informations aux fonctionnaires, sont au centre d’une tentative controversée à Washington et dans les bureaux gouvernementaux de la planification de remanier le système obsolète de financement des principales routes américaines.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le secteur généralement sans intérêt de la planification des grands axes a soudain provoqué un débat fort animé et des alliances mouvementées.\n",
      "REF   : The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\n",
      "BASE  : The generally uninterested sector in the planning of major axes suddenly provoked a lively debate and movement of alliances.\n",
      "CUSTOM: Le secteur généralement sans intérêt de la planification des grands axes a sudden provocé un débat fort animé et des alliances mouvementées.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les libertaires ont rejoint des groupes écologistes pour faire pression afin que le gouvernement utilise les petites boîtes pour garder la trace des miles que vous parcourez, et éventuellement de la route sur laquelle vous circulez, puis utiliser les informations pour rédiger un projet de loi fiscal.\n",
      "REF   : Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\n",
      "BASE  : Liberals have joined environmental groups to push for the government to use small boxes to keep track of the miles you travel, and possibly the road you travel, and then use the information to write a tax bill.\n",
      "CUSTOM: Les libertaires ont rejoint des groupes écologistes pour faire pression afin que le gouvernement utilise les petites boîtes pour garder la trace des miles que vous parcourez, et éventuellement de la route sur laquelle vous circulez, puis utiliser les informations pour rédiger un projet de loi fiscal.\n",
      "------------------------------------------------------------\n",
      "SRC   : Le Tea Party est atterré.\n",
      "REF   : The tea party is aghast.\n",
      "BASE  : The Tea Party has arrived.\n",
      "CUSTOM: The Tea Party is atterré.\n",
      "------------------------------------------------------------\n",
      "SRC   : L'American Civil Liberties Union est elle aussi très préoccupée et exprime son inquiétude concernant la protection de la vie privée.\n",
      "REF   : The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\n",
      "BASE  : The American Civil Liberties Union was also very concerned and expressed concern about the protection of privacy.\n",
      "CUSTOM: The American Civil Liberties Union is also very concerned and expresses son concern concerning the protection of the vie privée.\n",
      "------------------------------------------------------------\n",
      "SRC   : Et tandis que les membres du Congrès n'arrivent pas à se mettre d'accord pour savoir s'il faut continuer, plusieurs États n'ont pas attendu.\n",
      "REF   : And while Congress can't agree on whether to proceed, several states are not waiting.\n",
      "BASE  : And while members of Congress were unable to agree on whether to proceed, several States did not wait.\n",
      "CUSTOM: Et tandis que les membres du Congrès n'arrivent pas à se mettre d'accord pour savoir si il faut continuer, plusieurs États n'ont pas attendu.\n",
      "------------------------------------------------------------\n",
      "SRC   : Ils cherchent comment, au cours de la prochaine décennie, ils pourront passer à un système permettant aux conducteurs de payer en fonction du nombre de miles parcourus.\n",
      "REF   : They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\n",
      "BASE  : They are looking at how, over the next decade, they can move to a system where drivers pay based on the number of miles travelled.\n",
      "CUSTOM: They cherchent comment, au cours de la prochaine décennie, they pourront passer à un système permettant aux conducteurs de payer en fonction du nombre de miles parcourus.\n",
      "------------------------------------------------------------\n",
      "SRC   : Des milliers d'automobilistes ont déjà embarqué ces boîtes noires, parfois équipées d'un système de surveillance par GPS, pour une virée expérimentale.\n",
      "REF   : Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\n",
      "BASE  : Thousands of car drivers have already boarded these black boxes, sometimes equipped with a GPS surveillance system, for an experimental turn.\n",
      "CUSTOM: Des milliers d'automobilistes ont déjà embarqué ces boîtes noires, sometimes equipées d'un système de surveillance by GPS, pour une virée experimentale.\n",
      "------------------------------------------------------------\n",
      "SRC   : Cela est vraiment indispensable pour notre nation.\n",
      "REF   : This really is a must for our nation.\n",
      "BASE  : This is truly essential for our nation.\n",
      "CUSTOM: This is truly indispensable for our nation.\n",
      "------------------------------------------------------------\n",
      "SRC   : « Ce n'est pas comme si nous avions le choix », a déclaré Hasan Ikhrata, directeur général de la Southern California Association of Governments, qui prévoit que l'État commence à enregistrer les miles parcourus par chaque automobiliste californien d'ici 2025.\n",
      "REF   : \"It is not a matter of something we might choose to do,\" said Hasan Ikhrata, executive director of the Southern California Assn. of Governments, which is planning for the state to start tracking miles driven by every California motorist by 2025.\n",
      "BASE  : \"It's not like we have a choice,\" said Hasan Ikhrata, director general of the Southern California Association of Governments, who expects the state to start recording the miles driven by every Californian by 2025.\n",
      "CUSTOM: « Ce n'est pas comme si nous avions le choix », a déclaré Hasan Ikhrata, director general de la Southern California Association of Governments, who prevoit that l'État begins à enregistrer les miles parcourus par chaque automobiliste californien d'ici 2025.\n",
      "------------------------------------------------------------\n",
      "SRC   : Il va y avoir du changement dans la façon dont nous payons ces taxes.\n",
      "REF   : There is going to be a change in how we pay these taxes.\n",
      "BASE  : There will be a change in the way we pay these taxes.\n",
      "CUSTOM: There will be a change in the way we pay these taxes.\n",
      "------------------------------------------------------------\n",
      "SRC   : La technologie est là pour le faire.\n",
      "REF   : The technology is there to do it.\n",
      "BASE  : Technology is there to do that.\n",
      "CUSTOM: The technology is there to do.\n",
      "------------------------------------------------------------\n",
      "SRC   : La pression vient du fait que le Highway Trust Fund du pays, financé avec les taxes que les Américains paient à la pompe, est financièrement à sec.\n",
      "REF   : The push comes as the country's Highway Trust Fund, financed with taxes Americans pay at the gas pump, is broke.\n",
      "BASE  : The pressure comes from the fact that the country's Highway Trust Fund, funded with taxes paid by Americans on the pump, is financially dry.\n",
      "CUSTOM: The pressure comes from the fact that the Highway Trust Fund du pay, financed with the taxes that the Americans pay à la pompe, est financièrement à sec.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les Américains n'achètent plus autant d'essence qu'avant.\n",
      "REF   : Americans don't buy as much gas as they used to.\n",
      "BASE  : Americans are no longer buying as much gasoline as they used to.\n",
      "CUSTOM: The Americans don't buy plus as much d'essence as before.\n",
      "------------------------------------------------------------\n",
      "SRC   : Les voitures peuvent parcourir plus de miles avec un gallon.\n",
      "REF   : Cars get many more miles to the gallon.\n",
      "BASE  : Cars can travel more than miles per gallon.\n",
      "CUSTOM: The cars can parcour plus de miles with a gallon.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(source_sentences)):\n",
    "    print(f\"SRC   : {source_sentences[i]}\")\n",
    "    print(f\"REF   : {reference_translations[i]}\")\n",
    "    print(f\"BASE  : {all_translations[i]}\")\n",
    "    print(f\"CUSTOM: {all_translations_custom[i]}\")\n",
    "    # print(f\"Facebook: {all_translations_facebook[i]}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Optional: limit output (e.g., to first 20 examples)\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8100901,
     "sourceId": 12811235,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8102273,
     "sourceId": 12813501,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 431618,
     "modelInstanceId": 413885,
     "sourceId": 529120,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
